\chapter{Analýza}

V této kapitole se pokusíme analyzovat problémy výstavby a úpravy dotazovacího enginu dle zadání práce.
Zároveň poskytneme možná řešení daných problémů.
Budeme zde postupovat v několika krocích. 
Začneme obecným návrhem dotazovacího enginu a projdeme hlavní koncepty pro implementaci.
V druhém kroku zvážíme kroky vykonávání dotazů a postup výběru řešení částí \textit{Order by} a \textit{Group by}, které se budou vykonávat po dokončení prohledávání grafu v \textit{Match} části.
V třetím kroku provedeme analýzu úprav pro agregaci v průběhu vyhledávání. 
Součástí této části bude analýza algoritmů \textit{Order by} a \textit{Group by} pro dané úpravy. 
Pokud v nějaké ukázce použijeme jazyk C\# míníme tím jazyk C\# pro .NET Framework 4.8.

\section{Obecný pohled na dotazovací engine}

V naší představě je dotazovací engine určen pro práci nad grafem, který je celý obsažen v paměti, a to včetně vlastností elementů grafu.
Graf bude načten v definovaném formátu a následně na něm budou vykonávány dotazy.
Graf po načtení bude pouze statický, tedy nebude v něm docházet k žádným změnám.
Nad grafem se pak vykoná uživatelsky definovaný dotaz.
Dané omezení jsme zvolili, protože hlavním cílem je testovat pouze části \textit{Group by} a \textit{Order by}.
Vytvořit reálnou grafovou databázi by zabralo netriviální časové období.

Dotazovací engine chceme vyvinout tak, abychom s ním byli schopni pracovat na stolním počítači/notebooku, protože nám to umožní zjednodušit vývojové a testovací prostředí.
Z tohoto důvodu nám ale vzniká hlavní omezení, které je paměťové, jelikož celá aplikace bude obsažena v hlavní paměti.
Reálné grafy bývají značně obrovské, a navíc samotné zpracování dotazů zabere množství paměti i času (tj. ukládáme výsledky prohledávání nebo vytváříme skupiny výsledků).
Abychom mohli reálné grafy načíst a zpracovat, tak při vývoji dotazovacího enginu se budeme snažit upřednostnit nižší paměťovou náročnost před vyšším výkonem.

Při obecném pohledu na dotazovací engine jsme lokalizovali hlavní bloky výstavby, které musíme uvážit.
Jsou to: reprezentace grafu, načítání uživatelského dotazu, výrazy (expressions) a dotaz/vykonání dotazu.
Graf nám bude představovat grafovou databázi. 
Samotně pak určuje formát objektů, nad kterými je vykonán uživatelský dotaz.
Uživatelský dotaz se musí načíst do interní reprezentace.
Expressions slouží k výpočtu hodnot z uživatelsky zadaných výrazů.
Například v části \texttt{order by x.PropOne}, musíme vědět, jak reprezentovat výraz \texttt{x.PropOne} a získat jeho hodnotu. 
Na základě interní reprezentace se musí vytvořit struktury dotazu a definovat exekuční plán. 
Blok dotaz/vykonání dotazu pak musí navíc obsahovat dva módy.
A to upravené řešení a původní řešení.
Uživatel si při spuštění dotazovacího enginu bude moct vybrat požadovaný mód.

Samotná představa vykonávání je následovná.
Uživatel při spuštění aplikace vybere chtěný mód.
Aplikace po zapnutí načte graf z datových souborů.
Uživatel pomocí příkazové řádku zadá dotaz k vykonání.
Dotaz se vykoná a po dokončení uživatel může opět zadat další dotaz.
Myslíme, že zde není nutné složité grafické rozhraní, proto budeme dotazovací engine považovat za konzolovou aplikaci. 

\section{Reprezentace grafu} \label{anal.grafrep}

Musíme uvážit, jak reprezentovat graf.
Graf bude představovat grafovou databázi.
Z části \ref{requirements} jsou hlavními faktory námi zvolená podmnožina jazyku PGQL a že se jedná o Property graf.
Pro případy nejednoznačnosti označíme \verb+elType+ jako typ štítku a \verb+propType+ jako typ hodnoty vlastnosti.

\subsection{Elementy grafu a jejich typ}

Musíme zvažovat reprezentaci elementů grafu a jejich \verb+elType+.
V našem případě jsou elementy pouze vrcholy a orientované hrany.
\verb+elType+ definuje seznam vlastností na elementu. 
Vlastnosti jsou také typované.
Vrchol a hrana musí mít rozdílný \verb+elType+, ale samotné vlastnosti se mohou opakovat pro oba druhy elementů.
Každá hodnota vlastnosti musí být přístupná skrze daný element:

\begin{itemize}

\item Pokud držíme element grafu, musíme být schopni jej rozlišit od ostatních elementů.

\item Pokud držíme element grafu, musíme být schopni přistoupit k hodnotám jeho vlastností.

\end{itemize}

V naší představě je řešení následovné.
Elementy budou třídy.
Každý element grafu bude potomkem jednoho abstraktního předka a potomci si budou definovat svá specifika.
Potomek bude vrchol a hrana.
Předek si bude pamatovat unikátní \verb+ID+, abychom elementy dokázali rozlišit. 
Předek navíc bude znát svůj \verb+elType+. 
Bude se jednat o ukazatel na třídu.
Daná třída by reprezentovala pouze jeden \verb+elType+ a bude společná všem elementům majících daný \verb+elType+.
V třídě by byl obsažen seznam \verb+IDs+ elementů daného typu, jejich pořadí (např. dle vkládání do seznamu) a vlastností v podobě polí s hodnotami.
V daných polích budou hodnoty vlastností každého elementu ležet na pozicích určených dle jejich pořadí.
Pro náš případ nebudeme uvažovat situaci, kdy vlastnost pro nějaký element nemá definovanou hodnotu.
Vlastnost musí být přístupná skrze mapu/slovník, abychom k ní mohli rychle přistoupit.
Každé vlastnosti tedy přidělíme unikátní identifikátor, který bude klíčem mapy/slovníku.
Nyní pokud držíme element grafu, můžeme přistoupit k hodnotě jeho vlastnosti skrze ukazatel na danou třídu.
Samotný přistup pak může být realizován například generickou funkcí. 

\subsection{Struktury obsahující elementy}

Nyní musíme analyzovat jaké struktury by byly ideální pro uchovávání elementů grafu.
Musíme brát v potaz, že propojení mezi vrcholy pomocí hran přímo ovlivňuje vyhledávání v části \textit{Match}.
V průběhu vyhledávání v určitý moment vždy držíme odkaz na nějaký element grafu.
Na základě daného elementu musíme provést akci:

\begin{itemize}

\item Pokud držíme vrchol, musíme být schopni přistoupit k jeho hranám.
Hranám z/do něj. Daný přístup by měl být co nejrychlejší a neměl by obsahovat žádné iterace. 
V průběhu prohledávání grafu se z vrcholu musí projít skrze všechny jeho hrany. 

\item Pokud držíme hranu, musíme být schopni přistoupit ke koncovému vrcholu. 
V průběhu prohledávání grafu vždy vlastníme vrchol, než přistoupíme k jeho hraně a následně k jejímu koncovému vrcholu. 
Tímto můžeme vyloučit nutnost, aby hrana znala informaci o svém původu.

\item Pokud držíme element grafu, chceme být schopni přistoupit k jeho sousedním elementů v obsahující struktuře za předpokladu, že víme, jestli se jedná o hranu nebo vrchol. 

\end{itemize}

K vyřešení daných problému v naší představě bychom použili tři pole.
Pole vrcholů, pole \texttt{out} hran (ukazují na koncový vrchol hrany) a \texttt{in} hran (ukazují na počáteční vrchol hrany). 
Zde by bylo vhodné vytvořit nové potomky obecné hrany: \texttt{out} hrana a \texttt{in} hrana.
Hrany by si pamatovali svůj koncový vrchol.
Pro \texttt{in} hranu by to byl vrchol odkud vychází, aby bylo možné v momentě držení vrcholu projít skrze ni na vrchol další.
Tedy pro jednu hranu na vstupu budou existovat dva záznamy v daných polích, které se liší pouze koncovým vrcholem.
Abstraktní předek všech elementů by si měl nově pamatovat i svou pozici v daných polích pro rychlý přístup k jeho sousedům.
Každé pole tedy bude mít unikátní typ, který nám pomůže rozlišit k jaké situaci má dojít v průběhu prohledávání grafu.

Zbývá vyřešit vztah hran a vrcholů.
Řešení, které bychom chtěli zvolit, je mít hrany v polích seskupeny podle: vrcholů, odkud vycházejí (pole \texttt{out} hran), a  vrcholů, kam směřují (pole \texttt{in} hran).
Vrchol by si pak pamatoval rozsah svých hran v příslušných polích. 
Chceme-li procházet hrany vrcholu, stačí procházet pole \texttt{out}/\texttt{in} hran pomocí rozsahů uložených v daném vrcholu.
Tedy čtyř indexů.
Skrze indexy můžeme pak pole libovolně iterovat.

Uvažovali jsme nad různými alternativami. 
Mít jeden typ hrany obsahující všechny nutné informace.
Řešení je paměťově přijatelnější, ale nastává problém s přístupem k \texttt{in} hranám vrcholů.
Řešením by mohlo být vytvořit samostatné pole \texttt{out}/\texttt{in} hran pro každý vrchol. 
Daný přístup nám připadá výrazně náročnější z hlediska paměti, protože musíme vytvářet pole pro každý vrchol zvlášť. 

\subsection{Návrh vstupních grafových dat} \label{anal.vstup}

Vstupní soubory musí obsahovat informace nutné pro Property graf.
Budeme očekávat dva druhy souborů.
Soubory schémat \texttt{elType} a jejich vlastností.
Datové soubory pak budou obsahovat konkrétní data grafových elementů.
(Jedná se o návrh a finální specifikaci uvedeme v rámci implementace.)

\subsubsection{Soubory schémat} 

Protože každý element grafu má svůj \verb+elType+, budeme mít na vstupu dva soubory schémat. 
Jeden pro hrany a jeden pro vrcholy.
Schéma bude obsahovat informace o všech \verb+elType+ a jejich vlastností.
Pro \verb+elType+ je důležitý název a výčet vlastností.
Vlastnosti pak musí nést svůj název a \verb+propType+.
Vidíme, že se jedná jen o výčet \verb+(Název/Hodnota)+ dvojic.
V tomto případě se nám jeví nejvhodnější zvolit pro reprezentaci schémat formát JSON \citep{json}.
\verb+elType+ bude reprezentován JSON objektem. 
První položka objektu je \verb+Kind+, která představuje \texttt{Název} a její \texttt{Hodnota} udává jméno \verb+elType+.
Za ní bude následovat výčet vlastností.
Vlastnosti budou opět reprezentovány dvojicí \verb+(NázevVlastnosti/propType)+.
Každý JSON objekt tedy definuje jeden \texttt{elType}.
Všechny objekty pak budou obsaženy v JSON poli:
\begin{code}
Soubor obsahující schéma vrcholů:
[    { "Kind": "NodeX" }, 
     { "Kind": "NodeY", "Vlastnost1": "integer" } 
     { "Kind": "NodeZ", "Vlastnost2": "string", 
       "Vlastnost1": "integer" }  ]

Soubor obsahující schéma hran:
[    { "Kind": "EdgeX" }, 
     { "Kind": "EdgeY", "Vlastnost1": "integer" } ]
\end{code}
Pro vrcholy zde vidíme tři \texttt{elType} s názvy \texttt{NodeX}, \texttt{NodeY} a \texttt{NodeZ}.
První \texttt{elType} nemá definované vlastnosti, ale druhá má vlastnost \texttt{Vlastnost1} s typem \texttt{integer}.
Poslední definuje dvě vlastnosti.
\texttt{Vlastnost2} s typem \texttt{string} a za ní následuje opět \texttt{Vlastnost1} s typem \texttt{integer}.
Samotné vlastnosti se mohou opakovat, ale musí mít vždy stejný \texttt{propType}.
Následně identicky pro schéma hran.
Ačkoliv hrana i vrchol by mohli mít stejný \texttt{elType}, tak budeme vždy uvažovat, že jsou rozdílná.
Nicméně dovolíme, aby vrchol i hrana mohli mít stejnou vlastnost.
Nyní musíme říct, co konkrétně znamenají \texttt{integer} a \texttt{string}.
Jedná se o dva různé \texttt{propType}.
První budeme chápat jako 32-bitovou číselnou hodnotu (v C\# \texttt{Int32}).
A druhý jako řetězec (v C\# \texttt{string}).
Práce s řetězci je obecný problém a existuje mnoho znakových sad, proto bychom chtěli omezit vstupní řetězce na základní znaky ASCII v rozsahu hodnot 0 až 127.  
Dané dva druhy představují základní typy používané i v komerčních sférách, proto chceme omezit vstupní typy pouze na tyto dva.

\subsubsection{Datové soubory}

Samotná data budou obsažena opět ve dvou separátních souborech pro hrany a vrcholy.
Chtěli bychom reprezentovat konkrétní data pomocí jednoduchého textového souboru.
Každý řádek bude reprezentovat jednu hranu/vrchol.
V první řadě řádek musí obsahovat unikátní \verb+ID+ elementu a jeho \verb+elType+. 
Za \verb+elType+ následuje seznam hodnot vlastností v pořadí určených schématem.
To znamená, že první vlastnost v JSON objektu má hodnotu jako první v daném seznamu.
Pro hrany existuje na řádku navíc záznam \verb+ID+ vrcholů, které spojuje.
Tedy \texttt{ID} počátečního vrcholu (\texttt{fromID}) a \texttt{ID} koncového vrcholu (\texttt{toID}). 
Oddělovače mezi daty jsou implementační detail.
Pro naše účely se jedná o dostačující formát a poskytuje nám jednoduché možnosti načítání dat.
Pokud by docházelo v budoucnu k rozšířením, například víceslovné vlastnosti nebo XML vlastnosti, musí dojít k úpravě daných formátů.
Pro výše zmíněné schéma by datové soubory mohly vypadat následovně:
\begin{code}
Soubor hran (bez hlavičky a komentáře):
ID elType fromID toID Vlastnosti... 
50 EdgeX 0 0    // EdgeX nemá vlastnosti.
51 EdgeY 0 1 44 // EdgeY má vlastnost Vlastnost1
                // s číselnou hodnotou.
52 EdgeX 1 2   
\end{code}
\begin{code}
Soubor vrcholů:
ID elType Vlastnosti...
0 NodeX    // NodeX nemá vlastnosti.
1 NodeY 42 // NodeY má jednu vlastnost.
2 NodeZ Martin 22 // Dvě vlastnosti v pořadí
                  // definované schématem.
...
\end{code}

\section{Načítání uživatelského dotazu} \label{anal.parsing}

Analyzovali a navrhli jsme způsob reprezentace grafu společně s formátem datových souborů.
Samotné načítání je už implementační detail.
Nyní musíme analyzovat způsob získání informací z uživatelem zadaného dotazu. 
Uživatelský dotaz se pohybuje v rozsahu definovaném v sekci PGQL \ref{req.pgql}.
Nicméně, je zde nutné přemýšlet i nad možnými rozšířeními.
Například může dojít k přidaní částí \textit{Where} a \textit{Having} spolu s nutností porovnávání (\texttt{Where x.PropOne} \texttt{< 10}).
Proto se budeme snažit držet základních principů objektově orientovaného programování a volit vhodné návrhové vzory.

K načtení uživatelského dotazu se nám jeví jako nejvhodnější způsob použít techniky známé z překladačů programovacích jazyků.
Budeme vycházet ze základních principů knihy o překladačích \citep{dragonBook}.
V prvním kroku dojde k lexikální analýze uživatelsky zadaného řetězce.
Dojde k vytvoření tokenů.
V druhém kroku dojde k syntaktické a sémantické analýze tokenů.
Metodou top-down parsing \citep[str. 217]{dragonBook} se vytvoří stromová struktura reprezentující daný dotaz.
Poslední krok provede vytvoření tříd reprezentující dotaz pomocí iterace stromové struktury.
Iterace a sběr dat ze stromové struktury budou implementovány návrhovým vzorem Visitor \citep[str. 331]{patterns}.
V naší představě bychom chtěli vygenerovat stromovou strukturu pro každou hlavní část dotazu (\textit{Match}, \textit{Select}, \textit{Order by} a Group by).
Nyní bychom mohli sestavit Visitor pro každou část separátně a vyřadit tak nutnost jednoho globálního Visitoru.
Dané postupy nám pak umožní jednoduše pracovat s naší podmnožinou jazyka PGQL.

\subsection{Match a proměnné} \label{anal.mathcandvar}

Každá hlavní část dotazu po sesbírání informací pomocí Visitoru vygeneruje určité struktury.
Pro \textit{Match} se přímočaře naskytuje reprezentovat posloupnosti vrcholů a hran pomocí polí.
Každá posloupnost oddělená čárkou bude obsažena v samostatném poli.
Pole bude obsahovat třídy.
Třída si musí pamatovat jakou proměnou reprezentuje, \verb+elType+ pokud je definován a jde-li o hranu nebo vrchol.
Jedná se o všechny nutné informace, které můžeme následně využít k vytvoření vzoru prohledávání grafu.
Všimnout si musíme faktu, že \textit{Match} část definuje proměnné ve zbytku dotazu.
Během načítání dotazu musíme určit, zda se jedná o validní proměnnou a při výpočtech hodnot výrazů je nutné vědět přesně k jaké proměnné musíme přistoupit.
Problém se dá řešit vytvořením mapy/slovníku přístupných proměnných pro zbytek dotazu.
Proměnným pak můžeme přiřadit \verb+ID+.

\subsection{Select, Order/Group by}

Ostatní části \textit{Group by}, \textit{Order by} a \textit{Select} obsahují výrazy proměnných (např. \texttt{order by x}), přístup k vlastnostem proměnných (např \texttt{select x.PropOne}) a volání agregačních funkcí (\verb+min+, \verb+max+, \verb+avg+, \verb+sum+ a \verb+count+).
Proměnné zde představují elementy grafu.
Výrazy se však musí vyhodnotit za běhu programu.
Dalším problémem je, že výrazy mají různorodé návratové hodnoty.
Výraz \texttt{x} (\verb+ID+ vrcholu) lze chápat jako číselnou hodnotu.
Výraz \texttt{x.PropOne} má návratovou hodnotu dle \verb+propType+, který je definován ve vstupním schématu.
Agregační funkce \verb+min+, \verb+max+ mají návratovou hodnotu definovanou na základě jejich vstupních argumentů.
Funkce \verb+sum+ a \verb+count+ by měli ideálně pracovat s typem, který by předešel přetečení.
U \verb+avg+ se očekává hodnota s desetinnou čárkou.  
V budoucnu však může dojít k rozšířením a vyvstanou složitější výrazy, například aritmetické operace nebo zmiňované porovnání z \textit{Where/Having} části.
Problém nám usnadňuje fakt, že vlastnosti nesoucí stejné jméno mají stejný \verb+propType+.
Pokud ne, je nutné určit vhodnou návratovou hodnotu.
Navíc musíme brát v potaz, že daný výraz se nemusí vyhodnotit, například absence vlastnosti na vrcholu.
Proto jsme byli nuceni vymyslet systém výrazů (expressions).

\subsection{Expressions} \label{anal.expressions}

Systém vytváření a vyhodnocování výrazů efektivně za běhu je obecně složitý problém.
Omezíme se pouze na případy: přístup k proměnné, přístup k hodnotě vlastnosti proměnné a agregační funkce (\verb+min+, \verb+max+, \verb+avg+, \verb+sum+ a \verb+count+).

Základní myšlenka je reprezentovat výraz pomocí stromové struktury.
Obecně struktura bude využívat návrhový vzor Composite \citep[str. 163]{patterns}. 
Každý vrchol stromové struktury bude reprezentovat určitou akci.
Vrcholy budou výše vypsané výrazy. 
Na struktuře bude existovat metoda pro vyhodnocení.
Její návratová hodnota bude dvojice úspěch vyhodnocení + vypočtená hodnota.
Úspěch je zde důležitý, protože například můžeme přistupovat k neexistující vlastnosti. 
Dané struktury musí být pouze ke čtení, protože se budou využívat v paralelním prostřední.
Metody by se mohli libovolně dodávat při nutnosti použít novou strukturu k vyhodnocení výrazu. 

Následuje ukázka možného kódu v jazyce C\#:
\begin{code}
// Základní rodičovské třídy
abstract class Expression { }
abstract class ExpReturnValue<T>: Expression {
  public abstract bool TryEvaluate(Element[] elms, out T retVal); 
}
abstract class VariableAccess<T>: ExpReturnValue<T> {
     readonly int accessedVariableID; }
\end{code}

Třída reprezentující přístup k \verb+ID+ proměnné:
\begin{code}
class VariableIDAccess: VariableAccess<int> {
  public override bool TryEvaluate(Element[] elms, out int retVal) {
     retVal = elms[accessedVariableID].ID;
     return true; } }
\end{code}
Typ návratu funkce je definován pomocí \texttt{T} parametru třídy \texttt{ExpReturnValue}.
Volající tedy musí znát typ návratové hodnoty, aby funkci mohl vyhodnotit.
Třída \verb+VariableAccess+ nám poskytuje abstrakci pro přístup k proměnné.
Položka \verb+accessedVariableID+ určuje k jaké proměnné se má přistoupit.
Zde předpokládáme, že pole \verb+Element[]+ obsahuje proměnné přesně v pořadí, jak se vyskytly v části \textit{Match}.
Tedy pokud je zadán \texttt{match (x) -> (y)}, tak jeden výsledek prohledávání by bylo pole obsahující dva elementy \texttt{x} a \texttt{y}.
\texttt{Element} je zde chápán jako element grafu, tj. vrchol nebo hrana.
Na elementu existuje položka \texttt{ID} s unikátním identifikátorem elementu.
Funkce pak vrací hodnotu uloženou v \texttt{retVal} a úspěch vyhodnocení v návratové hodnotě. 
Jedná se pouze o ilustrační příklad. 
Výsledný formát definujeme v implementační části.

Případ přístupu k vlastnosti by mohl vypadat následovně:
\begin{code}
class VariablePropertyAccess<T>: VariableAccess<T> {
  reaonly int accessedPropertyID; 
  public override bool TryEvaluate(Element[] elms, out T retVal) {
    return elms[accessedVariableID].
               GetPropertyValue<T>(accessedPropertyID, out retVal);
  }
}
\end{code}
Zde dojde k volání metody na elementu grafu, který přistoupí k třídě reprezentující jeho \verb+elType+.
\texttt{accessedPropertyID} je identifikátor přistoupené vlastnosti.
Třída pak na základě existence vlastnosti vrátí hodnotu nebo neuspěje.
Tímto dokážeme vyřešit základní definované problémy.

\subsubsection{Agregační funkce}

Zbývá uvažovat, jakým způsobem reprezentovat agregační funkce.
Agregační funkce představují několik problémů.
Funkce je vypočtena pouze pro skupiny. 
Skupiny jsou vytvářeny v části \textit{Group by}.
Jejich návratové hodnoty jsou finální pouze po dokončení \textit{Group by}. 
Vstupem funkcí jsou výstupní hodnoty uživatelem zadaných výrazů.
Argument, dle kterého se aktualizuje agregovaná hodnota, je nutný znát pouze v době vykonání \textit{Group by}.
Dle naší představy je ideální vytvořit dva separátní koncepty.
První koncept bude zahrnovat výpočet hodnot argumentu společně s logikou agregační funkce.
Koncept bude reprezentován třídou, která vlastní stromovou strukturu dle předchozího příkladu.
Zároveň bude obsahovat logiku počítané funkce.
Například logika funkce \verb+min+ je porovnat dvě hodnoty a vybrat menší.
Na vstupu dané funkce pak bude úložiště hodnoty dané skupiny.
Všechny počítané agregační funkce zadané uživatelem označíme pomocí \verb+ID+.
Druhý koncept představuje nový potomek třídy \texttt{Expression}.
Daný potomek si pamatuje \verb+ID+ přistoupené agregační funkce a na vstupu očekává strukturu reprezentující skupinu.
K hodnotě počítané agregace přistoupíme pomocí její \verb+ID+.

Následuje ukázka prvního konceptu:
\begin{code}
abstract class Aggregation { }
abstract class Aggregation<T>: Aggregation {
  public ExpReturnValue<T> expr; // Argument ag. funkce.
  public abstract void Apply(ValueStorage storage, Element[] elms);
}
\end{code}
\begin{code}
public class Sum<T>: Aggregation<T>{
  public override void Apply(ValueStorage storage, Element[] elms) {
    if (expr.TryEvaluate(elms, out T retVal)) {
      storage.value += retVal;
    }
  }
}
\end{code}
\noindent Na ukázce výše vidíme položku \verb+expr+, která reprezentuje vstupní výraz agregační funkce.
Funkce \verb+Apply+ je logikou funkce. 
Vidíme funkci \verb+Sum+. 
Logikou je přičtení vypočítané hodnoty do poskytnutého úložiště, pokud dojde k úspěšnému vyhodnocení výrazu.

Následuje ukázka druhého konceptu:
\begin{code}
class GroupAggValueAccess<T>: ExpReturnValue<T> {
  reaonly int accessedAggFuncID; 
  public override bool TryEvaluate(Group group, out T retVal) {
    retVal = group.GetAggValue<T>(accessedAggFuncID);
    return true; }}
\end{code}
\verb+Group+ reprezentuje výsledky jedné skupiny.
\verb+accessedAggFuncID+ je identifikátor vypočítané agregační funkce.
Hodnota funkce se vrací pomocí \verb+GetAggValue<T>+.
Obecně ale vždy nemusí dojít k úspěchu vyhodnocení.
Při výpočtu se například vždy přistoupilo k neexistující vlastnosti u všech elementů.
Pomocí našeho návrhu pak můžeme vyřešit i budoucí rozšíření (např. zmíněné aritmetické operátory nebo porovnání).

Třídy pro binární sčítání mohou vypadat takto:
\begin{code}
class ExpressionBinOperation<T>: ExpressionReturnValue<T> {
  public ExpressionReturnValue<T> expr1;
  public ExpressionReturnValue<T> expr2;
}
class ExpressionIntegerAdd: ExpressionBinOperation<int>{
  public override bool TryEvaluate(Element[] elms, out int retVal) {
    if (expr1.TryEvaluate(elms, out int expr1Val) &&
        expr2.TryEvaluate(elms, out int expr2Val)) {
      retVal = expr1Val + expr2Val;
      return true;
    } else {
      retVal = default;
      return false;
    }
  }
}
\end{code}
Zde \texttt{ExpressionIntegerAdd} rozšiřuje obecný binární operátor a určuje návratovou hodnotu výrazu.
V těle funkce \texttt{TryEvaluate} dojde k pokusu o vyhodnocení dvou podvýrazů.
Při úspěchu dojde k vypočtení finální hodnoty a v opačném případě dojde k selhání vyhodnocení. 

Tímto jsme vyřešili problémy načítání a reprezentace expressions pro náš dotazovací engine.
Kód je pouze ilustrační a není finální.
Použili jsme jej, protože poskytoval lepší možnosti vysvětlení konceptu než obrázek.
Nyní přistoupíme k problémům vykonávání dotazu.

\section{Vykonání dotazu} \label{anal.vykonanidotazu}

Máme připravené obecné podklady.
Víme jak reprezentovat graf a jak budeme získávat informace z uživatelem zadaného dotazu.
Dotaz bude vykonán nad naší reprezentací grafu.
Abychom splnili zadání, tak \textit{Group/Order by} musí být vykonány po dokončení prohledávání grafu v \textit{Match} části.
Vylepšená řešení budou dané části vykonávat v průběhu vyhledávání.
V ideálním případě chceme dosáhnout toho, aby dotazovací engine poskytoval dva módy.
Mód zde reprezentuje způsob vykonání dotazu.
Uživatel dotazovacího enginu si při spuštění vybere chtěný mód.
Tudíž, módy musí v programu koexistovat.
V této části analyzujeme obecný model vykonání, který posléze v sekci \ref{anal.improvement} upravíme tak, aby vykonával \textit{Group/Order by} v průběhu prohledávání grafu.

Při zkoumání vlastností hlavních částí PGQL (sekce \ref{req.pgql}) jsme si uvědomili jejich separaci logiky z hlediska vykonávání dotazu.
Match prohledává graf a produkuje výsledky. 
\textit{Select} výsledky vypisuje. 
\textit{Order/Group by} třídí/seskupuje vyprodukované výsledky.
Filtrace výsledků je prováděna v části \textit{Where} a \textit{Having}.
Tedy dané části se mohou vyvíjet nezávisle na sobě a následně propojit dle priorit.

Priority (zleva největší):
\begin{code}
      Match > Where > Group by > Having > Order by > Select 
\end{code}
\textit{Match} vyprodukuje výsledky, \textit{Where} je filtruje, \textit{Group by} je seskupí, \textit{Having} opět filtruje, následně jsou setříděny a jako poslední krok se provede výpis uživateli.
Propojení pak tvoří primitivní exekuční plán.
Při podrobnějším zkoumání jsme zjistili, že dané schéma značně připomíná návrhový vzor Pipes and Filters \citep[str. 53]{patterns2}.
Ačkoliv v naší práci použitá podmnožina PGQL (sekce \ref{req.pgql}) neobsahuje \textit{Having} a \textit{Where}, tak jsme si vědomi provázanosti částí \textit{Match/Where} a \textit{Group by/Having}.
Pokud by byly v budoucnu implementovány, pak mohou být propojeny pro docílení lepší výkonnosti. 

Poznatky jsme se rozhodli aplikovat v našem návrhu.
Každá část dotazu bude reprezentována objektem (obrázek \ref{figure.diaQueryObjects}).
Metoda \verb+Compute+ implementuje logiku objektu.
Propojení se realizuje pomocí položky \verb+next+.
Dle uživatelského dotazu se vytvoří dané objekty a propojí dle priorit výše (obrázek \ref{figure.diaQueryObjectsCon}).
Propojení bude realizováno od nejmenší po největší, protože práce s nejvyšší prioritou je vykonána první a po dokončení její práce ji už nepotřebujeme.
Tedy můžeme uvolnit její zdroje.
Při vykonání se provede rekurzivní voláni funkce \texttt{Compute} na objektech v položce \verb+next+ (obrázek \ref{figure.diaQueryObjectsCall}). 

\begin{figure}[!htp]
\includegraphics{../img/diaQueryObjects.pdf}\centering
\caption{UML class diagram objektů představující části dotazu.}
\label{figure.diaQueryObjects}
\end{figure}

\begin{figure}[!htp]
\includegraphics{../img/diaQueryObjectsCon.pdf}\centering
\caption{Propojení objektů pomocí položky \texttt{next} pro dotaz\\* \texttt{select x match (x) order by x}.}
\label{figure.diaQueryObjectsCon}
\end{figure}

\begin{figure}[!htp]
\includegraphics{../img/diaQueryObjectsCall.pdf}\centering
\caption{UML activity diagram rekurzivního volání metody \texttt{Compute} pro dotaz \texttt{select x match (x) order by x}.}
\label{figure.diaQueryObjectsCall}
\end{figure}

\clearpage

\subsection{Paralelizace vykonání dotazu}

Poslední věc nutnou ošetřit je způsob paralelizace dotazu.
Existují dvě možnosti.
Paralelizace bude provedena pouze interně pro každý objekt nebo dojde k vypracování složitějšího modelu.
V naší představě bychom volili první variantu, díky které nebudeme potřebovat vytvářet závislosti mezi objekty.

\subsection{Formát výsledků} \label{anal.tables}

Mezi částmi dochází k předávání výsledků.
Výsledky musí mít definovaný formát, aby každá část dokázala správně provádět svou logiku zpracování.
V části \textit{Match} dochází ke generování obecných výsledků.
V části \textit{Group by} dojde k vytvoření skupin a výpočtů agregačních funkcí.
Pokud je v uživatelském dotazu zahrnuto \textit{Group by}, tak zbylé části musí očekávat jiný formát výsledků.
Daný formát musí obsahovat skupiny a výsledné hodnoty agregačních funkcí.

Obecné výsledky prohledávání grafu budeme ukládat do tabulky.
Jeden řádek tabulky bude reprezentovat jeden výsledek prohledávání.
Nyní musíme rozhodnout, jaké informace do tabulky uložíme.
V části \textit{Match} se pracuje s elementy grafu.
Jeden výsledek prohledávání obsahuje seznam elementů, které odpovídají hledanému vzoru.
Máme dvě možnosti jak daný výsledek zpracovat.
První varianta v části \textit{Match} při jeho nalezení vypočte hodnoty všech výrazů obsažených ve zbytku dotazu.
Sloupeček představuje hodnoty jednoho výrazu.
Tato varianta nám nepřišla vhodná, protože by objekt \textit{Match} musel znát informace o výrazech v celém dotazu.
Navíc výrazy v částech mohou být rozdílné.
Tedy se vytváří nutnost vytvářet sloupečky hodnot v momentě, kdy se nepotřebují a tím se navyšuje spotřeba paměti.

Příkladem může být dotaz: 
\begin{code}
select x.P1, ..., x.Pn match (x) -> (y) order by y.P1, ..., y.Pm  
n a m jsou přirozená čísla větší než 1
\end{code}
Zde vidíme množství výrazů.
Pokud bychom aplikovali první variantu, tak v \textit{Match} části musíme vygenerovat $m + n$ sloupců hodnot.
Z tohoto důvodu chceme zvolit jinou variantu.
Do tabulky budeme ukládat elementy grafu.
Sloupeček tabulky bude reprezentovat jednu proměnnou z části \textit{Match}.
Tedy tabulka má počet sloupečků rovný počtu unikátních proměnných. 
Pro stejný dotaz vytvoříme pouze dva sloupečky.
Abychom zamezili stejnému problému i z opačné strany (tj. mnoho proměnných a málo výrazů), tak budeme ukládat pouze proměnné, ke kterým se přistupuje v ostatních částech.
Tímto jsme vyřešili paměťový problém, ale nastal problém výkonnosti.
Vyvstává totiž nutnost vypočítávat hodnoty výrazů znova, přestože jsme je už v minulosti počítali (např. při třídění se několikrát porovnává stejný výsledek s jinými).
Problém se dá částečně řešit uchováváním výsledků, ale konkrétní řešení ponecháme na analýzu zbylých částí.
V tento moment jsme se rozhodli jít cestou menší paměťové náročnosti na úkor výkonnosti.
Pro výsledky \textit{Group by} můžeme opět v představě volit tabulku.
Jediný rozdíl bude, že řádek zde bude reprezentovat jednu skupinu (opět uložené elementy grafu) společně s vypočtenými hodnotami agregačních funkcí.

\subsection{Proxy třída jako řádek tabulky}

Musíme být schopni pracovat s řádky tabulek.
Pomocí řádků v tabulce se musí vyhodnotit výrazy v částech \textit{Group/Order by} a \textit{Select}.
Vstupním argumentem expression by měl být pouze jeden řádek.
Přesouvání řádku o více sloupcích je drahé.
Pro docílení efektivní práce s řádky budeme řádek reprezentovat proxy třídou.
Proxy třída bude návratová hodnota funkce hranatých závorek na třídě tabulky (\texttt{tabulka[i]}, kde \texttt{i} je index řádku).
Třída poskytne metody pro přístup k elementům nebo výsledkům agregačních funkcí ve sloupečcích pro daný řádek tabulky.
V ideálním případě si bude pamatovat pouze index reprezentujícího řádku a odkaz na tabulku.
Nyní pokud budeme chtít vyhodnotit výraz pro $i$-tý řádek tabulky, tak zavoláním funkce hranatých závorek na objektu tabulky dostaneme proxy třídu řádku a tu použijeme k vyhodnocení výrazu.

Analyzovali a navrhli jsme obecně způsob vykonání dotazu společně s formátem předávaných výsledků mezi částmi. 
Nyní přejdeme k analýze jednotlivých částí dotazu. 
V analýze jsme se rozhodli vynechat část \textit{Select}, protože není podstatná pro naši práci.

\section{Match a prohledávání grafu} \label{anal.match}

\textit{Match} část má za úkol najít všechny podgrafy v grafu odpovídající zadanému vzoru.
Vlastnosti prohledávání grafu jsou definované jazykem PGQL (sekce \ref{req.pgql}).
Vzor se vždy skládá z posloupností vrcholů a hran.
Na každý prvek posloupnosti se můžeme dívat jako na úložiště nějakého elementu grafu.

Vlastnosti prohledávání grafu:
\begin{itemize}

\item Výsledky prohledávání jsou podgrafy izomorfní se zadaným vzorem.
\item Hrana se může opakovat několikrát v rámci jednoho vzoru.
\item Proměnná hrany ve vzoru se může použít pouze jednou.
\item Dvě rozdílné proměnné mohou obsahovat stejný element.
\item Shodnost elementů se ověřuje pouze na opakující se proměnné.

\end{itemize}

\subsection{BFS vs DFS}

Hledání podgrafu v grafu je obecně složitý problém. 
Cílem této práce není navrhnout algoritmus pro vyhledávání podgrafu, proto jsme se rozhodli inspirovat a použít obecný postup k řešení daného problému.
Mezi základní postupy vyhledávání vzoru patří prohledávání do šířky (BFS) a prohledávání do hloubky (DFS) \citep[kap. 4]{graphAlg}. 
Na základě 1. a 2. kapitoly článku o distribuovaném zpracování PGQL dotazů \citep{asyncPGX} jsme vybrali algoritmus DFS, jelikož v průběhu prohledávání generuje menší množství mezivýsledků.
To je dáno chováním BFS.
BFS v každém kroku musí prozkoumat všechny sousedy políček z předešlého kroku.
Toho se docílí vložením nových sousedů do fronty (obecná struktura \texttt{queue} FIFO).
Fronta se tak rychle zvětšuje.
DFS naopak potřebuje znát sousedy pouze aktuálně prohledávaných vrcholů.

\subsection{Hledaný vzor a finální výsledek} \label{anal.match.res}

K aplikaci algoritmu musíme vytvořit strukturu (vzor) představující hledaný podgraf.
Strukturu budeme chápat jako propojené posloupnosti tříd.
Dané třídy obsahují informace specifikující vhodné elementy grafu, které jim májí náležet.
Cílem DFS je nalézt elementy grafu, které budou odpovídat hledaným posloupnostem.
V průběhu DFS prohledávání si vzor pamatuje aktuální třídu, pro kterou DFS hledá vhodný element.
V momentě průchodu DFS přes nějaký element se ověří, zda se jedná o vhodný element pro aktuální třídu.
Pokud ano, třída nyní reprezentuje daný element, DFS z něj pokračuje v prohledávání a dojde k přestupu na další třídu v posloupnosti.
Pokud ne, DFS se vrací na předchozí element v prohledávání, ze kterého vybere ještě neprozkoumaný element.

\subsubsection{Tvorba vzoru}

Nyní musíme strukturu vytvořit.
V sekci \ref{anal.mathcandvar} jsme uvedli, že posloupnosti oddělené čárkou v \textit{Match} části budou reprezentovány jako pole tříd obsahující informace o proměnných a hledaných elementech.
Tedy jedno pole je ekvivalentní jedné posloupnosti.
Pro zřetelnost budeme hovořit o jednom poli jako o řetězci.

Příklad dotazu se dvěma řetězci:
\begin{code}
match (x) -> (y), (x) -> (q)
\end{code}

Řetězce nám nyní budou sloužit k vytvoření vzoru.
Vzor budeme chápat jako pole obsahující řetězce z části \textit{Match}.
Výše jsme zmínili, že řetězce jsou také pole.
Vzor pro výše zmíněný příklad dotazu se dvěma řetězci bude vypadat následovně:
\begin{code}
vzor = [[(x), ->, (y)], [(x), ->, (q)]]
\end{code}
Zde \texttt{vzor} obsahuje dva řetězce.
\texttt{vzor[0]} obsahuje první řetězec.
\texttt{vzor[0][0]} představuje hledaný vrchol, který definuje proměnnou \texttt{x}.
\texttt{vzor[0][1]} představuje hledanou dopřednou hranu.
\texttt{vzor[0][2]} představuje hledaný vrchol, který definuje novou proměnnou \texttt{y}.
Ekvivalentně pro \texttt{vzor[1]}.
Tímto docílíme jednoduché iterace po struktuře vzoru.
Prohledávání bude probíhat zleva doprava.
První hledaný element je vrchol \texttt{x}.
Při úspěšném nalezení daného vrcholu dojde k DFS zanoření, které je symbolizováno přestupem na následující položku v řetězci, tj. hledáme dopřednou hranu z elementu proměnné \texttt{x}.
V momentě nalezení všech elementů prvního řetězce dojde k přestupu na další řetězec.
Zde prohledávání proběhne z již nalezeného vrcholu představující proměnnou \texttt{x}.
Po nalezení všech elementů druhého řetězce je získán výsledek prohledávání a následuje DFS vynoření, které je symbolizováno přestupem na předcházející položku v řetězci.
Obecně při úspěšném nalezení elementu probíhá DFS zanoření a při neúspěchu probíhá DFS vynoření.

Všimněme si, co se stalo při přestupu na druhý řetězec.
Prohledávání začalo z již nalezeného elementu proměnné \texttt{x}.
Abychom mohli toto provádět, musíme mít již nalezený element proměnné \texttt{x}.
Jelikož zadané řetězce v dotazu nemusí být na vstupu nijak setříděné, a navíc nemusí obsahovat opakující se proměnné, tak ze vstupních řetězců vytvoříme souvislé komponenty.
Souvislou komponentu chápeme jako skupinu řetězců, které se dají propojit pomocí sdílených proměnných.
Řetězce souvislé komponenty budou v poli \texttt{vzor} obsaženy za sebou tak, abychom vždy mohli navázat na následující řetězec pomocí již nalezených proměnných.

Příklad souvislé komponenty tří řetězců:
\begin{code}
      (1)         (2)                (3)
match (x) -> (y), (r) -> (q) -> (t), (y) -> (q)
\end{code}
Zde vidíme tři řetězce, které tvoří souvislou komponentu.
První řetězec lze propojit s třetím pomocí proměnné \texttt{y} a druhý řetězec lze propojit s třetím pomocí proměnné \texttt{q}.
Abychom při prohledávání mohli navázat již nalezenými elementy proměnných, upravíme pořadí řetězců na \texttt{(1)}, \texttt{(3)} a \texttt{(2)}.
Nyní při přestupu na další řetězec vždy spustíme prohledávání z již nalezeného elementu sdílené proměnné.
Problém však nastává v případě řetězce \texttt{(2)}, který obsahuje navazující proměnnou uprostřed.
Abychom mohli stále iterovat zleva doprava, tak daný řetězec rozdělíme na dva řetězce pomocí proměnné \texttt{q}.
První řetězec bude obsahovat třídy před danou proměnnou v převráceném pořadí (včetně převrácení hran) a druhý obsahuje třídy za danou proměnnou.
Oba řetězce budou začínat třídou reprezentující vrchol proměnné \texttt{q}. 
Nyní jsme schopni při přestupu na dva nové řetězce navázat již nalezeným elementem proměnné \texttt{q}.

Příklad rozdělení řetězce \texttt{(2)} pomocí proměnné \texttt{q}:
\begin{code}
(r) -> (q) -> (t) rozdělíme na (q) <- (r) a (q) -> (t)
Výsledný vzor pak je:
[[(x), ->, (y)], [(y), ->, (q)], [(q), <-, (r)], [(q), ->, (t)]]
\end{code}

Problém vyvstane, pokud nám vzniknou dvě separátní komponenty z jednoho dotazu.
Tento případ nastane právě tehdy, když pro dvě komponenty neexistuje proměnná, která by je propojila.
Například přidáním řetězce \texttt{(o) -> (s)} do výše zmíněného vzoru.
V takovém případě se můžeme dívat na dotaz jako na skalární součin výsledků prohledávání dvou komponent.
Již jsme zmínili, že řetězce souvislých komponent budou v poli vzoru umístěny za sebou.
Přidaný řetězec tedy bude obsažen na konci vzoru.
Případ, kdy nedokážeme při přestupu na následující řetězec navázat (tj. první řetězec jiné komponenty), vyřešíme následovně.
V momentě, kdy je nalezen podgraf odpovídající první komponentě, spustí se nové DFS prohledávání pro komponentu druhou.
Teprve až projdeme obě komponenty, výsledek se uloží do tabulky, protože v tuto chvíli budeme vlastnit finální výsledek prohledávání.
Zbavíme se tak nutnosti uchovávat mezivýsledky a následnému tvoření skalárního součinu.
Princip se aplikuje ekvivalentně pro více komponent.

\subsubsection{Finální výsledek}

V \textit{Match} části dotazu je součástí definice hledaného vzoru i specifikace proměnných.
Proměnné jsou přístupné v ostatních částech dotazu.
Finálním výsledkem prohledávání grafu bude pole elementů představující proměnné dotazu.
Toto pole bude obsaženo ve struktuře vzoru.
Jedna položka v poli odpovídá právě jedné proměnné.
Opakující se proměnné nemají více položek v poli.
Příkladem může být \texttt{match (x) -> (y) -> (x), (k) <- (p)}.
Tento hledaný vzor obsahuje čtyři proměnné: \texttt{x}, \texttt{y}, \texttt{k} a \texttt{p}.
Pole tedy obsahuje čtyři položky v pořadí daném prvním výskytem proměnné v dotazu.
Výsledně první položka v poli představuje proměnnou \texttt{x}, druhá položka proměnnou \texttt{y}, třetí \texttt{k} a poslední \texttt{p}.

Bude existovat pouze jedno pole pro jeden vzor. 
Nebudou se vytvářet další, ale budou se měnit pouze vnitřní elementy, protože chceme omezit režii za tvorbu polí.
Pole bude sloužit k ověření, zda držíme totožné elementy v momentě opakující se proměnné v průběhu prohledávání.
V momentě nalezení celého podgrafu bude pole proměnných zaplněné a bude chápáno jako finální výsledek prohledávání, protože pouze proměnné jsou přístupné v jiných částech dotazu.

\subsection{Průběh prohledávání grafu}

K nalezení všech podgrafů v grafu potřebujeme z každého vrcholu spustit DFS.
Při DFS se bude kontrolovat, jestli průchod odpovídá hledanému vzoru.
Procházení vždy začíná vrcholem, následně se přistoupí k hraně daného vrcholu a pak koncovému vrcholu hrany. 
K procházení grafu máme navrženou strukturu z sekce reprezentace grafu \ref{anal.grafrep}.
Pokud dojde k nalezení podgrafu, tak výsledek bude uložen způsobem z sekce \ref{anal.tables}.
V našem případě tedy překopírováním elementů z pole proměnných náležící vzoru.
\subsection{Paralelizace prohledávání grafu} \label{anal.matchPar}

Nyní přistoupíme k analýze paralelizace prohledávání grafu.
V paralelním řešení chceme použít co nejmenší počet synchronizačních primitiv.
Ukládání výsledků do společné struktury by způsobilo značnou režii za synchronizaci.
V ideálním případě bude probíhat prohledávání grafu lokálně, následně pak dojde k efektivnímu slévání výsledků.

Jako řešení jsme zvolili jeden ze základních způsobů.
Budeme paralelizovat prohledávání ze startovních vrcholů.
Vyhledávání bude reprezentováno objektem (\texttt{Matcher}).
\texttt{Matcher} vlastní strukturu reprezentující hledaný vzor (\texttt{Pattern}).
Každé vlákno bude vlastnit lokálně svůj \texttt{Matcher}, \texttt{Pattern} a svou tabulku výsledků.
Všechna vlákna budou sdílet thread-safe objekt (\texttt{VertexDistributor}), který jim bude přidělovat vrcholy grafu.
Vlákno vždy zažádá \texttt{VertexDistributor} o určitý počet vrcholů, ze kterých spustí lokálně prohledávání a výsledky uloží do své tabulky.
Nikdy nenastane situace, kdy dvě vlákna mají stejný startovní vrchol.
Po vyčerpání všech vrcholů grafu prohledávání končí.
V jednovláknovém řešení jsou přiděleny všechny vrcholy najednou danému vláknu. 
Rozložení objektů mezi vlákny je zobrazeno na obrázku \ref{figure.diaQueryObjectsMatchPar}. 

\texttt{VertexDistributor} je zde velice důležitý.
Musí rozdělovat malé části vrcholů.
Kdyby rozděloval velké části vrcholů může se stát, že některá vlákna budou mít mnohem více práce.
Děje se tak, protože reálné grafy nemají obecně rovnoměrné rozložení hran.
Jedno vlákno by mohlo dostat vrcholy nacházející se v oblasti s množstvím hran, zatímco jiné vlákno by procházelo řídkou oblastí.
Jelikož se rychle vyčerpaly startovní vrcholy, tak vlákno v řídké oblasti ukončí svou práci mnohem dříve něž vlákno první.
Nyní se musí čekat na dokončení práce prvního vlákna.
\clearpage
\begin{figure}[!htp]
\includegraphics{../img/diaQueryObjectsMatchPar.pdf}\centering
\caption{Diagram paralelizace prohledávání grafu.}
\label{figure.diaQueryObjectsMatchPar}
\end{figure}

\subsection{Slévání výsledků prohledávání} \label{anal.match.merge}

Po dokončení prohledávání grafu je nutno vyřešit slévání výsledků jednotlivých vláken.
Kdybychom ponechali výsledky bez úpravy, tak nedokážeme rovnoměrně rozdělit práci mezi vlákna v paralelních řešeních \textit{Order/Group by}.
Cílem je vytvořit jednu tabulku obsahující všechny výsledky.
K vyřazení překopírovávání všech výsledků vláken využijeme následující princip.
Sloupeček tabulky bude tvořen polem polí fixní délky.
Jeden sloupeček v programovacím jazyce C\# může vypadat takto: \texttt{List<Element[FixedArraySize]>}.
V kroku slévání nyní pouze překopírujeme odkazy na pole místo samotných výsledků.
Avšak, pořád nám zůstává nutnost překopírovat výsledky v posledních polích sloupečků, která jsou nezaplněná.
Volbou vhodné hodnoty \texttt{FixedArraySize} se bude překopírovávat pouze malé množství výsledků.
Konkrétní volba hodnoty je heuristická a vyplývá z vlastností grafu a počtu nalezených výsledků.
Pro naše účely během implementace zkusíme zvolit prvně $n/\log_2 n$ ($n = $ \#výsledků prohledávání) pro jednovláknové zpracování a pro paralelní zpracování $(n/\log_2 n)/\#vláken$.
$log_2 n$ odpovídá počtu alokací při plnění dynamického pole $n$ položkami.
Slévání bude probíhat opět paralelně.
Nabízí se dva způsoby.
Vlákno slévá pouze jeden totožný sloupeček všech výsledků vláken nebo dojde k dvoucestnému slévání výsledků vláken.
Správné řešení ponecháme na dobu implementace.    


\bigskip

\section{Order by} \label{anal.orderby}

\textit{Order by} si klade za cíl setřídit vyhledané výsledky z části \textit{Match} pomocí zadaných klíčů.
Pořadí klíčů určuje pořadí porovnání.
Výsledky se porovnávají zleva doprava.
To znamená, pokud jsou dva klíče stejné, postoupí se k porovnání s klíčem dalším.
Rovnost dvou výsledků nastává právě tehdy, když mají stejné hodnoty pro všechny klíče. 
Pro klíč se také definuje, jestli má třídění probíhat v rostoucím nebo klesajícím pořadí.
Výchozí pořadí je chápáno jako rostoucí. 
Potřebujeme určit jakým způsobem budou výsledky prohledávání setříděny.
Musíme vybrat algoritmus a následně navrhnout způsob efektivního třídění tabulky výsledků.

\subsection{Výběr algoritmů a paralelizace}

Existuje mnoho algoritmů pro třídění.
Chtěli bychom zvolit již prozkoumané a zároveň běžně používané třídící algoritmy.
Mezi náš výběr padli Merge sort nebo Quick sort.
Jsou ideální volba, protože pro ně již existují paralelní verze.
Při implementaci chceme ideálně použít již existující knihovny nebo implementace. 

\subsection{Quick sort vs Merge sort}

Uvedeme krátké porovnání na základě 3. kapitoly průvodce algoritmů \citep{labyrint}. 
Merge sort má časovou složitost $ \Theta(n\log n) $ i v nejhorším případě, zatímco Quick sort stejné složitosti dociluje pouze v průměrném případě.
V nejhorším případě má $\Theta(n^2)$.
Merge sort potřebuje $\Theta(n)$ pomocné paměti a je to stabilní třídící algoritmus.
Quick sort pouze $\Theta(\log n)$, ale nejedná se stabilní třídění.
K implementaci stabilního Quick sortu je potřeba $\Theta(n)$ pomocné paměti.
Quick sort značně závisí na výběru pivota.
V našem případě bude obtížné ho volit správně, protože nedokážeme říci nic o rozložení tříděných dat.
Z tohoto důvodu bychom volili raději Merge sort.  

\subsection{Třídění pomocí indexů}

Hlavním problémem \textit{Order by} je třídění tabulky výsledků.
V sekci \ref{anal.tables} jsme definovali formát výsledků a navrhli proxy třídy pro výpočet výrazů.
Setřídit tabulku v našem smyslu znamená setřídit řádky pomocí klíčů zadaných uživatelem.
Pro zjištění shodnosti dvou řádků musíme vypočítat hodnoty jejich klíčů pomocí výrazů a následně je porovnat.
Přesouvání řádků v tabulce, která má více než jeden sloupec, by představovalo značné zpomalení.
Uvedli jsme, že výrazy pro řádky dostanou na vstupu proxy třídu řádků.
Proxy třída se v naší představě získá voláním funkce hranatých závorek na objektu tabulky výsledků.
Daný princip nám umožní vytvořit pole indexů v rozsahu počtu řádek tabulky.
Indexy budou setříděny namísto pravých řádků vybraným algoritmem a při porovnání dojde k získání proxy tříd a výpočtu výrazů.
Přistup nám umožní vyřadit přesouvání řádků, ale zase potřebujeme lineární paměť na pole indexů.
Po dokončení třídění se pole použije jako indexační struktura.

\subsection{Optimalizace porovnání vlastností hodnot} \label{anal.orderby.opt1}

Třídění obvykle představuje opakované porovnání jednoho prvku s ostatními v řadě za sebou.
Pro pokaždé takové porovnání v řadě počítáme stejnou hodnotu výrazu opakovaně.
Porovnání pomocí \texttt{ID} pouze přistupuje k položce elementu grafu.
Problém nastane, když budeme porovnávat pomocí vlastností.
V takovém případě musíme přistoupit k tabulce \texttt{elType} (sekce \ref{anal.grafrep}), zjistit existenci přistoupené vlastnosti a následně přistoupit k její hodnotě.
Danou situaci můžeme vyřešit částečně uchováváním hodnot výrazů.
Budeme si pamatovat poslední porovnané řádky a jejich hodnoty výrazů.
Pokud dojde k porovnání řádků, pro který byl výraz již vypočítán, tak použijeme zachovanou hodnotu.

\subsection{Optimalizace porovnání stejných elementů} \label{anal.orderby.opt2}

Další možná optimalizace porovnání může nastat v případě, pokud pro použitý graf platí \#Vrcholů $<<$ \#Hran.
Daná vlastnost může mít za následek, že porovnávané řádky budou často obsahovat stejné elementy pro dotazy typu:
\begin{code}
select x.PropOne match (x) -> (y) order by x.PropOne;
\end{code}
V takovém dotazu by prohledávání grafu mělo vygenerovat několik výsledků se stejným elementem v proměnné \texttt{x}.
Počet takových výsledků zde odpovídá počtu hran vrcholů \texttt{x}.
Pokud bychom porovnávali dané výsledky, museli bychom pro ně vždy vypočítat hodnoty výrazů, ačkoliv výsledky obsahují stejné elementy.
Abychom předešli opakovanému výpočtu výrazů pro dané výsledky, vymysleli jsme optimalizaci.
Výsledky nejdříve porovnáme pomocí \texttt{ID} jejich elementů a teprve pak pomocí výrazů.
Tímto vyřadíme opakovaný výpočet výrazů pro výsledky se stejnými elementy.
Tedy využijeme dvou optimalizací.
Budeme si uchovávat poslední hodnoty výrazů a navíc omezíme porovnání výsledků se stejnými elementy.

\subsection{Optimalizace v paralelním prostředí}

Vymysleli jsme optimalizace porovnání.
Doteď jsme však předpokládali, že porovnání probíhá v jednom vlákně.
Druhá optimalizace funguje i v paralelním prostřední, protože se jedná pouze o čtení statických hodnot.
Avšak první optimalizace vytváří problém.
Dochází zde k uchovávání výsledků lokálních pro vlákno a existence sdíleného úložiště by vytvořila souběh.
Vlákna by se snažila číst a ukládat výsledky ze sdíleného úložiště a docházelo by k nedefinovanému chování.
Problém se dá vyřešit například tak, že každé vlákno bude vlastnit svoje objekty s hodnotami výrazů.
V průběhu implementace budeme muset najít vhodnou techniku ukládání, aby došlo ke zrychlení třídění.

\section{Group by} \label{anal.groupby}

\textit{Group by} seskupuje výsledky prohledávání grafu podle uživatelem zadaných klíčů.
Dva výsledky patří do stejné skupiny právě tehdy, když se shodují ve všech hodnotách klíčů.
Musíme být schopni vypočítat agregační funkce pro skupiny.
K tomu již máme navržené způsoby z sekce Expressions (\ref{anal.expressions}).
Zbývá nám vymyslet způsob ukládání mezivýsledku a algoritmy k vykonání.

\subsection{Módy Group by}

\textit{Group by} představuje dle našeho pohledu dva módy vykonání.
První mód obsahuje v dotazu část \textit{Group by} a libovolné množství agregačních funkcí.
Dojde k vytvoření skupin a výpočtu výsledků funkcí pro každou skupinu.
Tento mód budeme označovat \textbf{Group by}.
Druhý mód nemá v dotazu část \textit{Group by}, ale pouze agregační funkce v ostatních částech.
Zde automaticky dochází k předpokladu, že všechny výsledky patří do stejné skupiny.
Tedy je vytvořena pouze jedna skupina a pro ni se vypočtou hodnoty agregačních funkcí.
Mód nazveme \textit{Single group Group by}.


\subsection{Úložiště mezivýsledků agregačních funkcí} \label{anal.groupby.uloziste}

V sekci Expressions (\ref{anal.expressions}) jsme navrhli objekt, který obsahuje logiku výpočtu funkce a na vstupu dostává úložiště výsledku.
Očekává se, že pro každou skupinu bude existovat úložiště.
Úložiště musí obsahovat prostor pro výsledky všech počítaných funkcí.
Vymysleli jsme dva způsoby:

\begin{itemize}

\item \textbf{Bucket} - každá skupina bude vlastnit pole objektů. 
Pole bude mít délku rovnou počtu počítaných agregačních funkcí.
Objekty představují úložiště výsledků funkcí.

\item \textbf{List} - výsledky všech skupin jsou uchovávány ve dvou-dimenzionálním poli, tj. primitivní tabulce.
Sloupeček představuje výsledky agregační funkce.
Jedné skupině pak přináleží řádek v daném poli.
Nyní pokud budeme chtít výsledky funkcí skupiny, stačí přistoupit skrze přidělený index ke chtěnému výsledku.
\end{itemize}

Následuje ukázka možné implementace dle popisu výše v jazyce C\#:
\begin{code}
Bucket:
\\ Pole výsledků agregačních funkcí.
BucketResult[] groupAggFuncResults; 
\\ Objekt úložiště. 
class BucketResult {} 
\\ Objekt definující typ ukládané hodnoty.
class BucketResult<T>: BucketResult { T value; }

List:
\\ Jednoduchá tabulka výsledků agregačních funkcí.
ListResults groupsAggFuncResults;
\\ Objekt primitivní tabulky výsledků agregačních funkcí.
class ListResults { ListHolder[] holders; }
\\ Objekt jednoho sloupečku tabulky.
class ListHolder {}
\\ Objekt definující typ sloupečku.
class ListHolder<T> : ListHolder { List<T> values }
\end{code}

První způsob je náročnější na paměť oproti druhému způsobu, neboť je zde nutnost vytvářet objekty a pole pro každou skupinu.
Avšak, v druhém způsobu jsme nuceni přistupovat k výsledkům pomocí indirekce.
Výhoda Bucket spočívá v jeho jednoduchém přemisťování (chápeme-li pole jako odkaz) a izolaci od ostatních výsledků skupin.
V takovém případě jsme schopni přesouvat výsledky skupiny aniž bychom museli kopírovat jejich hodnoty.
Předpokládáme, že Bucket bude výhodnější pro paralelní zpracování díky izolaci od ostatních výsledků, jelikož počet skupin není dopředu znám.
V List budeme muset dynamicky rozšiřovat pole.
Při rozšíření nastane souběh, který budeme muset ošetřit.

\subsection{Logika agregačních funkcí}

Ještě než přistoupíme k výběru zpracování musíme analyzovat logiku agregačních funkcí.
Logika pak ovlivňuje co a jak se bude ukládat v úložišti výsledků.

\begin{itemize}
\item \texttt{min/max:} výsledek funkce je minimum/maximum pro skupinu. 
Při výpočtu dojde k porovnání a následnému uložení hodnoty.
V objektu výsledku musíme znát aktuální minimum/maximum.
Dále, byla-li hodnota již nastavena, protože musíme být schopni rozeznat prázdné úložiště po jeho vytvoření.


\item \texttt{count/sum:} výsledek je počet výsledků/součet hodnot výsledků. 
Při výpočtu musíme přičítat hodnotu k hodnotě v úložišti.

\item \texttt{avg:} výsledek je aritmetický průměr.
Při výpočtu si budeme ukládat počet výsledků a součet hodnot výsledků.
Dochází zde tedy k navýšení počtu výsledků a přičtení nové hodnoty ke stávajícímu součtu.
Pro získání finální hodnoty dojde k vypočtení podílu součtu a počtu výsledků.
\end{itemize}

\subsection{Jednovláknové zpracování} \label{anal.groupby.singlethread}

Po celou dobu budeme pracovat s tabulkou výsledků \textit{Match} části.
Pro vykonání \textit{Group by} se nám nabízí několik možností.
První možnost je řádky tabulky setřídit a následně při iteraci vytvářet skupiny a počítat agregační funkce.
Myslíme, že možnost přináší zbytečnou režii za porovnání při třídění, protože pro každé porovnání musíme vypočítat hodnotu výrazu.
Z tohoto důvodu chceme využít strukturu, která bude interně používat hašovací tabulku (C++ \texttt{std::map<Key, Value>} nebo C\#  \texttt{Dictionary<Key, Value>}).
Záznam v tabulce bude dvojice \texttt{key/value}. 
\texttt{key} je zde index do tabulky výsledků z \textit{Match} části (nikoliv proxy třída).
Chceme ukládat pouze index, abychom ušetřili paměť za ukazatel na tabulku.
Porovnání vyvolá získání proxy třídy a následně vyhodnocení výrazů.
\texttt{value} obsahuje strukturu pro výsledky agregačních funkcí.
Pro Bucket to bude pole objektů a pro List to bude index do tabulky výsledků agregačních funkcí.
Pro výsledek bude vypočítána haš na základě hodnot klíčů a následně použita při vložení do hašovací tabulky.
Pokud už je výsledek obsažen v tabulce, tak se pro \texttt{value} (pole nebo index) pouze aktualizují hodnoty výsledků agregačních funkcí.
V opačném případě bude vložen nový záznam s novou \texttt{value}.
Pro \textit{Single group Group by} stačí pouze iterovat skrze tabulku a počítat agregační funkce.

\subsection{Optimalizace při výpočtu haš hodnoty} \label{anal.groupby.opt1}

Minulý přístup nám nabízí jednu optimalizaci k ušetření opakovaného výpočtu hodnoty klíčů.
Hašovací tabulka při vložení dvojice v prvním kroku vypočte hodnoty klíčů a vypočte jejich haš.
Výsledek se vloží do patřičné přihrádky.
Pokud nastala kolize, tak se prvky musí porovnat.
Při tomto porovnání se opět musí vypočíst hodnoty výrazů vkládané dvojice.
Zde můžeme využít předchozího výpočtu haš hodnoty.
Budeme uchovávat hodnoty výrazů a následně je znovu použijeme při porovnání.
Nicméně, pravděpodobně budeme potřebovat vytvořit závislost mezi objektem počítajícím haš hodnotu a objektem provádějícím porovnání.
Stejný princip jsme použili při optimalizaci porovnání v sekci \ref{anal.orderby.opt1}.
Nastávají pro něj také stejné problémy v paralelním prostředí.

\subsection{Paralelní zpracování} \label{anal.groupby.paralel}

Chceme zvolit několik řešení s rozdílnou úrovní synchronizace, protože nevíme, které bude dosahovat nejrychlejších výsledků.
Navíc nám větší počet řešení umožní lépe porovnat vylepšená řešení.
Pro paralelní zpracování jsme vymysleli tři přístupy: \textbf{Global}, \textbf{Two-step} a \textbf{Local + dvoucestné slévání} (všechny budou schopny pracovat s úložišti Bucket i List).
Každý z nich začíná rozdělením tabulky výsledků \textit{Match} na ekvivalentní části.
To si můžeme dovolit, neboť máme tabulku obsahující všechny výsledky prohledávání grafu.
Každé vlákno dostane danou část ke zpracování.
Tím zaručíme rovnoměrnost práce mezi vlákny.
Samotná práce vláken pak závisí na zvoleném přístupu.
Specifika vykonání jsou popsána v následujících sekcích.

\subsection{Thread-safe agregační funkce}

Ještě než přistoupíme k popisu jednotlivých řešení, je důležité si uvědomit nutnost vytvořit thread-safe verzi objektů implementující logiku agregačních funkcí.
Pro každou funkci bude existovat ekvivalent thread-safe metody zpracovávající logiku funkce.
Samotně pak vyvstává nutnost implementovat thread-safe metody pro slévání výsledků agregačních funkcí.
Problém vyřešíme přidáním metod do objektů logiky agregačních funkcí.
Pro úpravu logiky agregačních funkcí na thread-safe verze volíme tyto varianty:

\begin{itemize}

\item \texttt{min/max:} princip \textit{Compare and Exchange}. V momentě porovnání mohlo dojít ke změně hodnoty v úložišti.
Musíme znovu provést porovnání.  

\item \texttt{sum/count:} tyto metody implementují pouze přičítání. 
V ideálním případě chceme použít atomické operace přičtení.
 
\item \texttt{avg:} tuto funkci budeme implementovat stejně jako původní funkci. 
Budeme si ukládat součet hodnot zpracovaných výsledků a jejich počet.
Navýšení hodnot provedeme opět atomickým přičtením jako u funkcí \texttt{sum} a \texttt{count}.
Finální hodnota pak bude podíl součtu a počtu hodnot.
\end{itemize}

\subsection{Global Group by} \label{anal.groupby.global}

Všechna vlákna budou provádět ekvivalent jednovláknového zpracování pomocí thread-safe paralelní mapy/slovníku (C\# \texttt{ConcurrentDictionary}).
Skupiny se vytváření globálně.
Všimněme si nutnosti dvojité synchronizace.
Prvně musí dojít k synchronizaci vytváření záznamů v mapě.
Druhý krok synchronizace je nutný při zpracování agregačních funkcí.
Paralelní mapa nám vyřadí souběh při vytváření nových záznamů skupin.
V momentě zpracování agregačních funkcí musí dojít k volání thread-safe verzí.
Výhoda tohoto přístupu je, že zde nedochází ke slévání výsledků.

Bucket reprezentace úložiště má zde značnou výhodu vůči List.
List musí dynamicky rozšiřovat tabulku svých výsledků.
Místo abychom použili dvojí synchronizace jako u Bucket, tak zde bude nutné představit ještě třetí krok synchronizace.
Při přístupu do tabulky je nutné kontrolovat, jestli se nemusí rozšířit.
V ten moment se musí zabránit přístupu ostatních vláken a teprve pak rozšířit tabulku.
To se dá implementovat například semaforem (C\# \texttt{Semaphor}) omezující pohyb vláken v kritické sekci.
Vlákno v momentě nutnosti rozšíření zablokuje vstup přes semafor.
Vlákno se na přístup pokusí projít skrze semafor.
Pokud je mu vstup zabráněn, tak dochází k rozšiřování tabulky.
V opačném případě aktualizuje výslednou hodnotu agregační funkce.
Postup s List může být však značně pomalý, proto budeme uvažovat, jestli přístup raději implementovat pouze pro Bucket.

Řešení \textbf{Global} je znázorněno na obrázku \ref{figure.diaGlobalGr}.
Část rozdělení práce ukazuje přidělení rovnoměrného počtu výsledků vláknům.
V globální části vlákna seskupují přídělené výsledky pomocí globální mapy výsledků (paralelní mapy).

\begin{figure}[!htp]
\includegraphics{../img/diaGlobalGr.pdf}\centering
\caption{Diagram paralelizace řešení \textbf{Global}.}
\label{figure.diaGlobalGr}
\end{figure}

\subsection{Two-step Group by} \label{anal.groupby.twostep}

Tento přístup probíhá ve dvou krocích.
Lokální část následovaná globální částí. 
V lokální části pro každé vlákno běží kompletně identický ekvivalent jednovláknového zpracování.
Globální část nastane v momentě dokončení této práce.
Místo aby vlákno ukončilo běh, tak rovnou provede slévání svých výsledků do thread-safe paralelní mapy.
To znamená, že vlákno nečeká na dokončení práce ostatních vláken, ale rovnou slévá své výsledky do paralelní mapy.
Tento přístup kombinuje jednovláknové řešení společně s přístupem \textbf{Global}.
Mínus je, že zde musí docházet ke slévání.
Plus je, že v prvním kroku se využívají metody, které neobsahují synchronizaci. 
Problematická část je zde slévání výsledků s List úložištěm výsledků agregačních funkcí.
První fáze nepředstavuje problém. 
Druhá představuje problém jako u \textbf{Global} řešení, tedy platí vše, co jsme pro něj zmínili.
Můžeme zkusit implementovat stejné řešení jako u \textbf{Global} pomocí semaforu.

Řešení \textbf{Two-step} je znázorněno na obrázku \ref{figure.diaTwoGr}.
Část rozdělení práce ukazuje přidělení rovnoměrného počtu výsledků vláknům.
V lokální části vlákna seskupují přidělené výsledky pomocí lokální mapy výsledků.
V globální části dochází ke slévání lokálních výsledků vláken pomocí globální mapy výsledků (paralelní mapy).

\begin{figure}[!htp]
\includegraphics{../img/diaTwoGr.pdf}\centering
\caption{Diagram paralelizace řešení \textbf{Two-step}.}
\label{figure.diaTwoGr}
\end{figure}


\subsection{Local + dvoucestné slévání Group by} \label{anal.groupby.local}

Přístup nepoužívá thread-safe metody ani paralelní mapu.
Opět rozdělíme přístup na dvě části.
V prvním kroku pro každé vlákno běží identický ekvivalent jednovláknového zpracování.
Po dokončení se spustí dvoucestné slévání výsledků vláken.
Slévání bude připomínat binární strom.
Listy představují lokální seskupování vláken.
Vnitřní vrcholy stromu představují slévání výsledků.
Finální výsledek je vytvořen v kořeni.
U slévání využijeme paralelního zpracování.
Při slévání vždy jedno vlákno ukončí běh, druhé z dvojice provede slévání a postoupí ke kořeni. 
Hlavní výhody byly už zmíněny.
Nevýhoda řešení je, že vlákna musejí čekat při slévání na dokončení práce druhého vlákna a teprve až pak může dojít ke slévání.
Další nevýhoda nastane v případě velkého počtu vláken.
Strom slévání v tuto chvíli bude hluboký a tedy výsledky vláken se budou často překopírovávat. 

Řešení \textbf{Local + dvoucestné slévání} je znázorněno na obrázku \ref{figure.diaLocalGr}.
Část rozdělení práce ukazuje přidělení rovnoměrného počtu výsledků vláknům.
V lokální části vlákna seskupují přidělené výsledky pomocí lokální mapy výsledků.
V globální části dochází k dvoucestnému slévání lokálních výsledků vláken.



\begin{figure}[!htp]
\includegraphics{../img/diaLocalGr.pdf}\centering
\caption{Diagram paralelizace řešení \textbf{Local + dvoucestné slévání} pro 4 vlákna.}
\label{figure.diaLocalGr}
\end{figure}

\subsection{Paralelizace Single group Group by} \label{anal.groupby.singlegroup}

K paralelizaci \textit{Single group Group by} využijeme jíž zmíněných principů.
Konkrétně zde mají využití všechny tři.
Problémem \textbf{Global} přístupu je synchronizace mnoha vláken na jednom místě.
Ideálnější je využít lokálního zpracování zbylých dvou přístupů.
Opět řešení rozdělíme na dva kroky. 
V prvním kroku každé vlákno provádí ekvivalent jednovláknového zpracování bez vytváření skupin, tj. počítá pouze agregační funkce pro jednu skupinu.
Výsledky se následně musí slévat.
K rozhodnutí, které řešení finálně použít použijeme fakt, že počet výsledků k slévání je roven počtu vláken.
V takovém případě nebudeme implementovat paralelní slévání, ale pouze jedno vybrané vlákno provede sjednocení všech výsledků.




\bigskip
Analyzovali jsme a navrhli řešení vykonání částí \textit{Match}, \textit{Group by} a \textit{Order by}.
Tímto jsme dokončili analýzu a návrh dotazovacího enginu.
Daná analýza a návrh nám poskytnou odrazový můstek při analýze úprav pro vykonání částí \textit{Group by} a \textit{Order by} v průběhu prohledávání grafu.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Úprava dotazovacího enginu} \label{anal.improvement}

Cílem úprav je poskytnout dotazovacímu enginu schopnost provádět části \textit{Group by} a \textit{Order by} v průběhu prohledávání grafu části \textit{Match}.
Obecně to znamená, že v momentě nalezení jednoho výsledku jej musíme okamžitě zpracovat.
Pro \textit{Order by} to znamená výsledek správně zatřídit do již setříděné posloupnosti výsledků.
Pro \textit{Group by} to znamená výsledek přidat do správné skupiny nebo pro něj skupinu vytvořit, a navíc musíme pro něj zpracovat agregační funkce. 
Čili, výsledky v průběhu prohledávání \textit{Match} části nebudeme ukládat do tabulky, která se po nalezení všech výsledků předá k dalšímu zpracování.
Namísto toho navrhneme postup, kterým docílíme zpracování výsledků v momentě jeho nalezení.
Postupy ověříme vůči stávajícím řešením v kapitole Experiment \ref{expr} z hlediska doby vykonání.
V ideálním případě docílíme zrychlení nebo pouze vyrovnání vůči řešením vykonávající \textit{Order by} a \textit{Group by} po dokončení prohledávání grafu.
Z hlediska implementace to také znamená naprogramovat vylepšení tak, abychom byli schopni jednoduše přepínat mezi způsobem vykonání dotazu.
Řešení tedy musí fungovat nezávisle na sobě. 
V prvním kroku úprav musíme získat obecný pohled na pozměněný způsob vykonání dotazu.
Následně v dalších krocích budeme navrhovat části dotazu konkrétněji.

\subsection{Pohled na pozměněný způsob vykonání dotazu}

V následujících sekcích popíše náš obecný pohled na zpracování dotazu.
Budeme vycházet z sekce \ref{anal.vykonanidotazu}.
V dané sekci jsme si definovali prioritu částí dotazu.
Priorita určovala pořadí vykonání:
\begin{code}
Match > Where > Group by > Having > Order by > Select
\end{code}
\textit{Match} se provedl jako první.
Následně se nalezené výsledky předávali dalším částem ve směru klesající priority.
Nejvyšší priorita se nachází nalevo a nejnižší napravo.
Pro naše potřeby úprav budeme nyní uvažovat pouze části \textit{Match}, \textit{Group by}, \textit{Order by} a \textit{Select}.
Opět budeme o částech uvažovat jako o separátních objektech.
Potřebujeme, aby \textit{Match} část v momentě nalezení výsledku jej předala k zatřídění části \textit{Order by} nebo k seskupení části \textit{Group by}.
Po zatřídění/seskupení se opět pokračuje v prohledávání grafu, dokud se nenajde další výsledek a ten se zase předá k dalšímu zpracování.
Můžeme si všimnout značné podobnosti s předchozím návrhem. 
Jediný rozdíl je ten, že místo předání všech výsledku najednou další části se předá výsledek pouze jeden.
Na \textit{Match} část se můžeme dívat jako na kontinuální generátor výsledků. 
V momentě nalezení se výsledek pošle dalším částem.
Zbylé části pak pouze čekají na moment příchozího výsledku.
Finální výsledky budou uchovány v objektech částí \textit{Group by} nebo \textit{Order by}. 

Otázkou je, co je zde předávaný výsledek.
Budeme předpokládat, že předávaný výsledek ke zpracování je pole proměnných definované v sekci hledaného vzoru \ref{anal.match.res}.
To znamená, že předané pole se nesmí měnit, protože pole náleží struktuře vzoru.
Tedy pokud s ním chceme pracovat přímo, tak musíme vytvořit kopii.
Když budeme hovořit o výsledku prohledávání, tak máme na mysli dané pole proměnných.

\subsection{Order/Group by část jako bariéra}

Problematická sekce návrhu je část \textit{Select}.
Pokud dotaz neobsahuje další části, pak v době nalezení výsledku jej stačí pouze vypsat.
Nicméně, pokud je v dotazu obsažen \textit{Group by} nebo \textit{Order by}, pak se výsledky mohou vypsat až po dokončení třídění nebo seskupování.
Tedy dané dvě části nám tvoří bariéru, skrze kterou se nemůže posílat výsledky dále.
Jelikož máme navrhnout pouze vykonání částí \textit{Order by} a \textit{Group by}, tak budeme uvažovat pro \textit{Match} a \textit{Select} stejný návrh, jako v minulých sekcích.
Tedy dotaz bude tvořen původní částí \textit{Select} propojenou s částí \textit{Match}.
Část \textit{Match} pak propojíme s částmi \textit{Order/Group by} a upravíme tak, aby jim byla schopna předávat jeden výsledek v momentě jeho nalezení.  

\subsection{Změna objektů reprezentující části Order/Group by}

Řekli jsme, že budeme opět považovat části dotazu za separátní objekty.
Vytvoříme nové objekty částí \textit{Group/Order by} reprezentující nový způsob zpracování.
Abychom byli schopni pracovat souběžně i s původními objekty, tak potřebujeme upravit objekt \textit{Match}.
Reprezentanty částí \textit{Order by} a \textit{Group by} budou nyní nové objekty (obrázek \ref{figure.diaStreamedResultProcessor}).
Budou si implementovat logiku zpracování jednoho výsledku v metodě \texttt{ProcessResult}.
Objekt zároveň obsahuje finální výsledky dotazu, proto potřebujeme metodu \texttt{RetrieveResults} na jejich získání.

Dotaz bude reprezentován opět řetězcem jako před úpravou zpracování.
\textit{Select} a \textit{Match} budou tvořit propojení objetků na základě UML diagramů \ref{figure.diaQueryObjects} a \ref{figure.diaQueryObjectsCon}.
Propojení objektu \textit{Match} s novými objekty \textit{Group by} a \textit{Order by} navrhneme v dalších částech.

\begin{figure}[!htp]
\includegraphics{../img/diaStreamedResultProcessor.pdf}\centering
\caption{UML class diagram nových objektů reprezentující části \textit{Group by} a \textit{Order by}.}
\label{figure.diaStreamedResultProcessor}
\end{figure}

\subsection{Propojení nových objektů s objektem Match}

Vytvořili jsme nové objekty a nyní je musíme propojit s objektem \textit{Match}.
Objekty budou propojeny na dvou úrovních.
První úroveň bude přímé spojení nových objektů s objektem \textit{Match} a druhá úroveň bude propojení vyhledávání a zpracování výsledku.

\subsubsection{Přímé spojení objektů} \label{anal.improvement.con1}

Popíšeme realizaci první úrovně propojení, tj. objekt \textit{Match} drží odkaz na objekt \textit{Group/Order by}.
Abychom realizovali tuto úroveň, tak musíme upravit objekt \textit{Match}.
Objekt \textit{Match} rozšíříme o chápání logiky nových objektů (obrázek \ref{figure.diaStreamedQueryObjects}).
Stávající objekt \textit{Match} jsme v naší představě pouze rozšířili a nevytvářeli kompletně nový objekt, protože propojení s \textit{Select} objektem je realizováno stále původním způsobem.
Finální propojení objektů je pak znázorněno na obrázku \ref{figure.diaStreamedQueryObjectsCon}.

\begin{figure}[!htp]
\includegraphics{../img/diaStreamedQueryObjects.pdf}\centering
\caption{UML class diagram rozšířeného objektu \texttt{newMatch} části \textit{Match}. Objekt nyní drží přímý odkaz na \texttt{ResultProcessor} a zároveň implementuje původní logiku objektu.}
\label{figure.diaStreamedQueryObjects}
\end{figure}

\begin{figure}[!htp]
\includegraphics{../img/diaStreamedQueryObjectsCon.pdf}\centering
\caption{Diagram objektů upraveného vykonání dotazu \texttt{select x match (x) order by x}. Plná šipka znázorňuje původní propojení a tečkovaná šipka představuje nové propojení.}
\label{figure.diaStreamedQueryObjectsCon}
\end{figure}

\subsubsection{Propojení vyhledávání a zpracování výsledku} \label{anal.improvement.con2}

Musíme ještě navrhnout způsob předávání výsledků částem \textit{Order/Group by} v průběhu prohledávání grafu.
Způsob musí být použitelný pro paralelní zpracování, proto budeme rovnou přemýšlet nad paralelním řešením.
V naší představě budeme vycházet přímo z původního návrhu z sekce \ref{anal.match}.
Definovali jsme si, že každé vlákno vlastní lokálně strukturu vzoru \texttt{Pattern}, objekt vyhledávání \texttt{Matcher} a tabulku výsledků.
Finální výsledky ukládá do tabulky a po dokončení prohledávání grafu dojde k slévání tabulek.
Zde upravíme část, ve které dochází k ukládání výsledků do tabulky.
Vlákno bude držet odkaz na objekt \textit{Group/Order by} a v momentě nalezení výsledek předá pomocí volání metody \texttt{ProcessResult}.
Metoda výsledek zpracuje a po návratu z metody se pokračuje ve vyhledávání.
To se opakuje dokud prohledávání grafu neskončí.

Zpracování dotazu bude finálně vypadat následovně.
Na řetězci objektů se zavolá metoda \texttt{Compute}.
První objekt v řetězci je \textit{Select}.
\textit{Select} rekurzivně zavolá metodu na části \textit{Match} a ta spustí vyhledávání.
Část \textit{Match} prohledává graf a výsledky předává části \textit{Order/Group by} pomocí metody \texttt{ProcessResult}.
Po dokončení prohledávání grafu volaná metoda \texttt{Compute} na objektu \textit{Match} získá zpracované výsledky z další části pomocí volání metody \texttt{RetrieveResults}.
Výsledky se tímto předají části \textit{Select} k vypsání uživateli. 

\subsection{Alternativní řešení}

Při výběru tohoto řešení jsme uvažovali ještě nad možností, ve které by vlákna vyhledávání pouze předávali pouze do fronty.
Další část by pouze zpracovávala výsledky z fronty.
Myslíme, že tohle řešení by bylo neefektivní v našem případě, protože by muselo docházet k synchronizaci fronty, tj. problém producent a spotřebitel.
V našem řešení jsme synchronizaci při předávání výsledků zcela vynechali.

Vytvořili jsme nové objekty částí \textit{Order by} a \textit{Group by}.
Propojili jsme původní objekty s novými a nyní přejdeme k analýze a návrhu samotných způsobů vykonání \textit{Order by} a \textit{Group by}.

\subsection{Obecný model vykonání Order/Group by}

Pokud bychom realizovali pouze jednovláknové vykonávání, tak bychom z předchozích sekcí měli již kompletní návrh.
Pomocí volání metody \texttt{ProcessResult} dojde k předání výsledků a následnému zpracování.
Problematická část je paralelizace vykonání.
Musíme být schopni zpracovávat výsledky z množství vláken v jeden okamžik.
Je nutné, aby docházelo k synchronizaci.
Ještě než přistoupíme ke konkrétním návrhům algoritmů zpracování, tak navrhneme obecný model paralelního zpracování.
Vymysleli jsme dva modely.
Modely \textbf{Half-Streamed} a \textbf{Streamed}.
Modely jsme vybrali na základě množství využívané synchronizace a množství slévání výsledků.
Chceme vytvořit větší množství řešení, abychom mohli lépe porovnat výsledky v kapitole Experiment \ref{expr}.

\subsubsection{Návrh Half-Streamed}

Prvním modelem vykonání je model \textbf{Half-Streamed}.
Myšlenkou tohoto návrhu je příchozí výsledky zpracovat ve dvou krocích.
V prvním kroku každé vlákno výsledky zpracovává lokálně.
Po dokončení vyhledávání dojde ke slévání výsledků vláken.
Vycházíme z řešení \textbf{Two-step} a \textbf{Local + dvoucestné slévání} \textit{Group by} z sekcí \ref{anal.groupby.twostep} a \label{anal.groupby.local}.
Výhodou tohoto přístupu je využití zpracování bez nutnosti synchronizace vláken v prvním kroku.
Nevýhoda je, že zde dochází ke slévání výsledků po dokončení zpracování.

Nyní jsme si uvědomili problém vznikající voláním metody \texttt{ProcessResult}.
Logika zpracování náleží objektům \textit{Group by} a \textit{Order by}.
Objekty zde musí vědět, že dochází nejdříve k lokálnímu zpracování.
Proto jsme rozšířili metodu o další formální parametr \texttt{MatcherID}.
Parametr symbolizuje \texttt{ID} vyhledávače (\texttt{Matcher}) vlákna.
Objekty \textit{Group by} a \textit{Order by} pak budou vlastnit lokální výsledky vláken, které budou přístupné skrze \texttt{MatcherID}.
Při volání metody \texttt{ProcessResult} dojde ke zpracování výsledku nad danými lokálními výsledky.
Po dokončení dojde ke slévání výsledků vláken.

\subsubsection{Návrh Streamed}

Druhým modelem vykonání je model \textbf{Streamed}.
Myšlenkou tohoto návrhu je příchozí výsledky zpracovat globálně.
Vycházíme z \textbf{Global} zpracování \textit{Group by} z sekce \ref{anal.groupby.global}.
Vytvoříme strukturu, která nám poskytne metody se synchronizací.
Všechna vlákna v momentě nalezení výsledku volají metodu \texttt{ProcessResult}, uvnitř které dojde k volání synchronních metod na struktuře.
Výhoda tohoto přístupu je odstranění nutnosti slévání výsledků vláken.
Nevýhoda je, že zde dochází k volání metod se synchronizací.

\section{Úprava Order by} \label{anal.improvement.orderby}

Cílem \textit{Order by} by je setřídit výsledky prohledávání.
V původním řešení jsme měli značnou výhodu, protože v momentě začátku třídění jsme vlastnili všechny výsledky prohledávání (tj. kompletní tabulka výsledků).
Místo třídění samotných řádků tabulky jsme třídili pole indexů.
Na pole indexů pak stačilo aplikovat základní třídicí algoritmus.
Nyní nevlastníme všechny výsledky.
Výsledky jsou generovány a zpracovány postupně.
V následujících sekcích navrhneme způsob zpracování \textit{Order by} v průběhu prohledávání grafu.

\subsection{Obecný princip zpracování}

V naší představě zpracování budeme udržovat setříděnou posloupnost výsledků prohledávání.
Při nalezení výsledku výsledek zatřídíme do již setříděné posloupnosti.
Obecně jsme se rozhodli použít následující princip.
Bude existovat totožná tabulka výsledků prohledávání jako v původním řešení společně s indexační strukturou tabulky, protože nechceme přesouvat řádky tabulky.
Indexační struktura bude opět obsahovat indexy řádků v tabulce.
Výsledek \textit{Order by} pak bude tabulka výsledku s indexační strukturou.

Výsledek prohledávání v momentě nalezení je vložen na nový řádek tabulky výsledků.
Následně je index nového řádku tabulky zatříděn do indexační struktury.
Z tohoto principu budeme vycházet v našem návrhu.
Nejdříve budeme analyzovat způsob jednovláknového zpracování a následně jednotlivé módy paralelního zpracování.

\subsection{Jednovláknové zpracování} \label{anal.ordeby.single}

Určili jsme, že tabulka výsledků je totožná s původní.
Výsledek je vložen na nový řádek tabulky a index je zatříděn do indexační struktury.
Potřebujeme jen navrhnout způsob zatřídění indexu do indexační struktury.
Uvažovali jsme nad dvěma základními přístupy.
První kombinuje pole indexů s binárním vyhledáváním.
Druhý přistup využívá vyhledávací stromy.
Přístupy popíšeme a následně provedeme malý experiment.

\subsubsection{Pole indexů + binární vyhledávání}

Myšlenka přístupu je udržovat setříděné pole indexů. 
V momentě nalezení výsledku je využito binární vyhledávání \citep[str. 26]{labyrint} k nalezení vhodného místa vložení do pole.
Prvek je vložen do pole.
Pokud se na místě nacházel již nějaký prvek, prvek je posunut doprava.
Pokud v poli není dostatek místa, tak je rozšířeno.
Jedná se vlastně o algoritmus Insert sort (třídění vkládáním).
Jediným rozdílem je, že k nalezení místa vložení se používá binární vyhledávání.

Problém zde představuje posouvání prvků v poli.
Předpokládáme-li, že prvky posouváme napravo, tak v nejhorším případě vložením na začátek pole posuneme všechny prvky.
V naší představě bychom chtěli problém řešit rozmístěním mezer mezi prvky v poli.
Mezerou zde rozumíme prázdný záznam, tj. neobsahuje žádný index tabulky výsledků.
Mezi každými dvěma sousedními prvky by existoval stejný počet prázdných záznamů.
Vložení by bylo opět realizováno binárním vyhledáváním.
V situaci posouvání prvků nyní stačí posouvat prvky do první mezery.
Řešení však naskýtá spoustu otázek.
Například neznáme ideální počet mezer mezi prvky a nevíme jak optimálně navrhnout binární vyhledávání na takovém poli.
Navíc zvyšováním počtu mezer se pole značně zvětšuje, tj. roste paměťová složitost.

\subsubsection{Vyhledávací stromy}

Druhý přístup využívá vyhledávací stromy \citep[str. 177]{labyrint}.
Chtěli bychom využít základní druhy vyhledávacích stromů jako binární vyhledávací stromy nebo $(a, b)$-stromy.
Výhoda $(a, b)$-stromů je ta, že každý vrchol stromu obsahuje vícero klíčů, zatímco binární vyhledávací stromy drží pouze jeden klíč ve vrcholu.
Pokud bychom implementovali řešení s vyhledávacími stromy, tak budeme ideálně chtít využít již stávajících knihoven.

\subsubsection{Experiment pole vůči vyhledávacím stromům}

K porovnání dvou přístupů jsme se rozhodli provést jednoduchý experiment.
Cílem testu je otestovat rychlost vkládání prvků do vybraných datových struktur.
Test bude částečně simulovat reálnou činnost zatřiďování prvků do struktury.
Experiment jsme naprogramovali v jazyce C\# jako konzolovou aplikaci Visual Studia 2019.
Kód je součástí příloh \ref{prilohy.benchtreevsarray}.
Kód jsme přeložili pro platformu Windows 10 x64 využívající .NET Framework 4.8.
Samotný hardware testovacího stroje je rozepsán v sekci metodiky \ref{expr.hw}.
K otestování jsme vybrali dvě nativní struktury C\#:

\begin{enumerate}
\item \texttt{List}: reprezentuje případ zatřiďování do pole binárním vyhledáváním.
\item \texttt{SortedSet}: reprezentuje případ binárního vyhledávacího stromu.
\end{enumerate}
Struktury jsme zaplnili $n$ náhodně generovanými prvky.
Prvky byly generovány nativní třídou \texttt{Random} s inicializační hodnotou 100100 v rozsahu hodnot $[10$ 000; \texttt{Int32.MaxInt}$ - 10$ $000]$.
Struktury byly setříděny.
Následně jsme do struktur vkládali $m$ náhodně generovaných prvků (totožnou třídou \texttt{Random}) z dvou různých rozsahů:

\begin{enumerate}
\item Rozsah $[0; 10$ $000]$ a je označen $front$. 
Umožní nám vkládat prvky na začátek setříděné posloupnosti. 
Sledujeme nejhorší případ pro pole, kdy dochází k posouvání všech prvků doprava.
\item Rozsah $[10$ $000;$ \texttt{Int32.MaxInt}$ - 10$ $000]$ a je označen $random$.
Umožní nám sledovat vkládání prvků do náhodných pozic struktury.
\end{enumerate}
Měřili jsme pouze část vkládání $m$ prvků do struktur pomocí třídy \texttt{Stopwatch}.
Měření jsme opakovali desetkrát pro každý rozsah a vybrali průměr hodnot.
Při každém opakování byly struktury znovu sestaveny.
Parametry $n$ a $m$ jsme volili tak, abychom byli schopni sledovat chování při zvyšování počtu vložených a vkládaných prvků. 

\subsubsection{Výsledky}

Výsledky se nacházejí v tabulce \ref{tab.orderbyexpr1}.
Z tabulky vidíme, že vkládání prvků do pole pomocí binárního vyhledávání značně zaostává, proto jsme se rozhodli upustit od myšlenky pole s mezerami.

\begin{table}[!htb]
\centering
\begin{tabular}{lD{.}{,}{1.4}D{.}{,}{1.4}D{.}{,}{2.4}D{.}{,}{1.4}D{.}{,}{3.4}D{.}{,}{1.4}}
\toprule
\mc{} & \multicolumn{2}{c}{$n=10^6$} & \multicolumn{2}{c}{$n=10^7$} & \multicolumn{2}{c}{$n=10^8$} \\
\mc{} & \mc{\texttt{List}} & \mc{\texttt{SSet}} & \mc{\texttt{List}} & \mc{\texttt{SSet}} & \mc{\texttt{List}} & \mc{\texttt{SSet}} \\
\midrule
\textit{random} $10^2$   & 0.0335  & 0.0001  &  0.464  & 0.0001   &   4.327   &  0.0001        \\
\textit{random} $10^3$   & 0.3312  & 0.002   &  4.470  & 0.0011   &  44.148  &  0.0016    \\
\textit{random} $10^4$   & 3.1092  & 0.006   & 43.999 &   0.0117   & 440.254  &  0.0155    \\
\textit{front} $10^2$    & 0.883   & 0.0001  &  0.879  & 0.0001   &   8.673  &   0.0001     \\
\textit{front} $10^3$    & 0.8729  & 0.0001  &  8.793  & 0.001    &  87.396  &  0.001    \\
\textit{front} $10^4$    & 9.6823  & 0.0049  & 87.856 &   0.0119   & 885.589  &  0.0117   \\
\bottomrule
\multicolumn{4}{l}{\footnotesize \textit{Pozn:}
\texttt{SSet} = \texttt{SortedSet}}
\end{tabular}
\caption{Výsledky testu vkládání v sekundách \texttt{List} vůči \texttt{SortedSet}.
Hodnota za názvem testu představuje parametr \textit{m}.}
\label{tab.orderbyexpr1}
\end{table}


\subsubsection{Experiment (a, b)-strom vůči SortedSet}

Na základě výsledků jsme se rozhodli naimplementovat $(a, b)$-strom \citep[str. 190]{labyrint}, u kterého jsme upravili definici na $b=2a$.
Pro experiment jsme určili parametr $a=128$, protože jsme díky němu dosahovali nejrychlejších výsledků.
Strom jsme porovnali vůči struktuře \texttt{SortedSet} při stejných testech, ale pouze pro nejvyšší řády počtu prvků stavby a vkládání.

\subsubsection{Výsledky}


Výsledky jsou zobrazeny v tabulce \ref{tab.orderbyexpr2}.
Z tabulky vidíme, že při vkládání prvků je rychlejší $(a, b)$-strom.
Pro finální rozhodnutí, kterou strukturu zvolíme k zatřiďování, jsme rozhodli provést poslední experiment.
Tentokrát budeme měřit první část vkládání $n$ prvků do prázdné struktury (test je označen \textit{build}).
Výsledky jsou v tabulce \ref{tab.orderbyexpr3}.
Vidíme, že v experimentu je rychlejší \texttt{SortedSet}.
Situaci si vysvětlujeme režií za operaci vložení do $(a, b)$-stromu, při které dochází k častému překopírovávání prvků v momentě vytváření nového vrcholu.
Nicméně, v průběhu experimentu jsme sledovali paměťové vytížení procesu pomocí nativního nástroje \texttt{Memory Usage} Visual Studia 2019.
Ukázalo se, že v průběhu testu \texttt{SortedSet} dosahovalo využití paměti $6,8$\,GB, zatímco $(a, b)$-strom pouze $2,1$\,GB.
Daný jev je způsoben vytvářením nové třídy pro každý vložený prvek do struktury \texttt{SortedSet}.
Finálně jsme se rozhodli zatřiďování realizovat pomocí $(a, b)$-stromu.

\begin{table}[!htb]
\centering
\begin{tabular}{lD{.}{,}{1.4}D{.}{,}{1.4}}
\toprule
\mc{} & \multicolumn{2}{c}{$n=10^8$} \\
\mc{} & \mc{\texttt{SortedSet}} & \mc{\texttt{$(128, 256)$-strom}} \\
\midrule
\textit{random} $10^4$   &  0.0155  & 0.014   \\
\textit{random} $10^5$   &  3.992  & 1.338   \\
\textit{front} $10^4$    & 0.0117  & 0.002  \\
\textit{front} $10^5$    & 1.483  & 0.483  \\
\bottomrule
\end{tabular}
\caption{Výsledky testu vkládání v sekundách \texttt{SortedSet} vůči $(128, 256)$-strom.
Hodnota za názvem testu představuje parametr \textit{m}.}
\label{tab.orderbyexpr2}
\end{table}

\begin{table}[!htb]
\centering
\begin{tabular}{lrr}
\toprule
\mc{} & \mc{\texttt{SortedSet}} & \mc{\texttt{$(128, 256)$-strom}} \\
\midrule
\textit{build} $n=10^8$   &  59,890  & 101,421   \\
\bottomrule
\end{tabular}
\caption{Výsledky testu stavby struktur v sekundách \texttt{SortedSet} vůči \\*$(128, 256)$-strom.}
\label{tab.orderbyexpr3}
\end{table}

\subsection{Ukládání prvků v (a, b)-stromu} \label{anal.improvement.orderby.storeindex}

V minulé sekci jsme rozhodli, že zatřiďování nalezených prvků prohledávání provedeme pomocí $(a, b)$-stromu.
Musíme definovat chování v případě, kdy nějaké dva prvky sdílí stejnou hodnotu třídění.
Předpokládejme, že ve stromě existuje index s určitou hodnotou klíče.
Prohledávání nalezne výsledek a uloží jej do tabulky a následně index řádku vloží k zatřídění do stromu.
V takovém případě dva indexy se budou jevit jako shodné.
Avšak, stále potřebuje mít indexy setříděné, čili v momentě shodnosti klíčů třídění budeme třídit prvky pomocí samotných hodnot indexů.
To můžeme, protože každý index řádku existuje pouze jednou v tabulce.
Čili nedojde k porušení setříděnosti.

Nyní jsme si uvědomili jednu možnou optimalizaci.
Optimalizace bude fungovat v případech, kdy se hodnoty třídění často opakují.
Každý záznam ve stromě bude obsahovat dvojici \texttt{(index, pole)}.
\texttt{index} je index řádku tabulky.
\texttt{pole} je datová struktura pole.
Pokud vkládáme prvek, který ještě není ve stromě, tak se pro prvek vytvoří daná dvojice.
Pole bude prázdné a položka \texttt{index} je index právě vkládaného řádku.
Pokud vkládáme prvek, který už se nachází ve stromě, tak prvek pouze vložíme do příslušného pole.
Tímto způsobem omezíme počet prvků ve stromě a tím i počet porovnání.

Nyní navrhneme způsob paralelizace třídění pro naše módy zpracování.
V průběhu návrhu se budeme snažit využít jíž získané informace z předchozí sekce.

\subsection{Řešení Half-Streamed} \label{anal.improvement.orderby.halfstreamed}

Samotný model zpracování \textbf{Half-Streamed} nám nabízí využít zatřiďování pomocí zmíněných stromů.
V prvním kroku každé vlákno bude lokálně vytvářet svou tabulku výsledků a indexační strom.
Problematická část je zde slévání výsledků.
Informace zde jsou uloženy ve stromech.
Všechny struktury bychom mohli průběžně iterovat a udržovat si minimum z aktuálních výsledků.
Budeme vlastnit separátní pole, do kterého na jeho konec ukládáme minima v každém kroku iterace.
Po dokončení iterace pole bude obsahovat výsledek slévání.
Bohužel jsme nepřišli na jednoduchý způsob paralelizace tohoto řešení, proto jsme se rozhodli od něj upustit.

Místo toho využijeme již několikrát zmiňované dvoucestné slévání (použili jsme jej při paralelizaci \textit{Group by} v sekci \ref{anal.groupby.local}).
V momentě dokončení prohledávání všemi vlákny se vytvoří jedno pole a každé vlákno do něj překopíruje své výsledky.
Zde budeme muset překopírovat proxy třídy řádků a nikoliv pouze jejich indexy, protože existuje zde mnoho tabulek a sléváním pouhých indexů nedokážeme rozeznat, jaké tabulce přináleží.
To znamená, že pole obsahuje posloupnosti výsledků vláken.
Následně se posloupnosti slévají po dvojicích, jako ve zmiňovaném řešení \textit{Group by}. 
Nevýhoda tohoto řešení je nutnost čekat na dokončení práce prohledávaní grafu všech vláken.
 
\subsection{Řešení Streamed} \label{anal.improvement.orderby.streamed}

Zatřiďování do globální struktury je mnohem komplikovanější problém.
Avšak, stále zde využijeme již nevržené principy tabulek a stromů.
Připravíme určité množství přihrádek.
Každá přihrádka bude obsahovat tabulku výsledků prohledávání a indexační strom.
Přihrádka bude přístupná pouze skrze zámek.

Třídění probíhá na základě klíčů zadaných uživatelem.
Klíče jsou vlastnosti elementů grafu.
Vlastnosti mají svůj typ (např. číselná hodnota \texttt{integer} nebo řetězec \texttt{string}).
V momentě implementace dotazovacího enginu typ vlastnosti je definován konkrétním typem programovacícho jazyka.
Pro jazyk C\# číselná hodnota může být typ \texttt{Int32} a řetězec typ \texttt{string}.
Dané typy mají své rozsahy hodnot.
Například pro \texttt{Int32} je rozsah hodnot $[$\texttt{Int32.MinValue}; \texttt{Int32.MaxValue}$]$.
Rozsahem hodnot zde míníme uzavřený interval na množině celých čísel.
Interval budeme označovat anglickým značením, tj. $[a; b]$ pro uzavřený, kde $a$ a $b$ jsou celá čísla a $a\leq b$.
Rozsah typu \textbf{prvního} klíče rozsekáme na části obsahující ideálně shodný počet prvků. 
Nyní každé přihrádce přiřadíme jednu část rozsahu. 
Přihrádky tedy budou tvořit ostré uspořádání.

Dále bude existovat objekt sdílený všemi vlákny, který pro každý výsledek určí přihrádku na základě jeho hodnoty prvního klíče.
Tedy vlákno při zatřiďování přistoupí k sdílenému objektu.
Ten na základě hodnoty prvního klíče výsledku určí jeho přihrádku.
Vlákno uzamkne zámek dané přihrádky, následně vloží výsledek prohledávání do tabulky a index nového řádku uloží do indexačního stromu.
Zámek se po zatřídění odemkne a vlákno pokračuje v prohledávání grafu.
Jsme si vědomi, že rozdělování celého rozsahu typu programovacího jazyka není ideální, protože nám nic neříká o konkrétních hodnotách vlastností v grafu.
Nicméně, daný postup chceme vyzkoušet, protože se dané hodnoty dají jednoduše pro graf vygenerovat.
Pokud bychom zjistili, že daný přístup je dostatečně rychlý, tak bylo vhodné v budoucích rozšířeních zvážit vytvoření statistik rozsahu konkrétních hodnot vlastností.

Nyní musíme zodpovědět několik otázek.
Musíme určit, kolik přihrádek budeme vytvářet.
Jak budeme rozdělovat rozsahy klíčů a jak určíme správnou přihrádku pro výsledek prohledávání.
Pro jednoduchost nebudeme uvažovat případ, kdy existuje pouze jedna přihrádka nebo práci vykonává pouze jedno vlákno.
Nejdříve si definuje formálně základní zmíněná označení:

\begin{itemize}

\item $P$ je množina všech přihrádek.

\item $|P|$ je počet přihrádek, kde $|P|\geq2$.

\item $p_i$ je přihrádka $i$, kde $i=0, 1, 2 ..., |P|-1$.

\item $t$ je počet vláken prohledávající graf, kde $t\geq2$, $t\leq64$ a $t$ je mocnina dvou.

\item $R=[a; b]$, kde $a$ a $b$ jsou celá čísla a $a\leq b$, je uzavřený interval rozsahu hodnot typu klíče třídění.

\item $R_i$ je uzavřený podinterval intervalu $R$, kde $i=0, 1, 2, ..., |P|-1$.
Přihrádce $p_i$ náleží podinterval $R_i$.
Mějme podintervaly $R_i=[a_i; b_i]$ $a_i\leq b_i$ a $R_j=[a_j; b_j]$ $a_j\leq b_j$, pak $\forall i$ a $\forall j$, takové že $i<j$ a $i\neq j$ platí $a_i<a_j$, $b_i<a_j$, $a_i<b_j$ a $b_i<b_j$.
Uvažujeme, že každý podinterval má alespoň jeden prvek, tedy $R$ obsahuje dostatek prvků.

\end{itemize}

\subsubsection{Počet přihrádek}

Ideální počet přihrádek je těžké odhadnout.
Obecně platí, čím více přihrádek tím je menší šance, že se dva vlákna setkají u jednoho zámku.
Proto počáteční odhad přihrádek určíme jako $|P|=t^2$.
Abychom nemuseli pracovat s obecným počtem přihrádek, omezili jsme počet přihrádek na 4096 ($t=64$).

\subsubsection{Rozdělování rozsahu}

Rozhodli jsme se, že rozdělení přihrádek budeme provádět pouze podle prvního klíče třídění.
Cílem je rozdělit rozsah typu programovacího jazyka na části stejné velikosti tak, aby tvořili ostré uspořádání dle poznámek výše.
Pro jednoduchost budeme přetvářet konkrétní rozsahy na rozsah $R=[0, n]$ $n \ge 0$, s kterým dále budeme pracovat.
Dále přihrádce $p_i$ přináleží po rozdělení část rozsahu $R_i$.
Jako základní typy vlastností jsme v sekci vstupních dat \ref{anal.vstup} zvolili číselné hodnoty (\texttt{integer}) a řetězce (\texttt{string}). 
Nyní se pokusíme demonstrovat způsob rozdělení rozsahu typů v jazyce C\# pro .NET Framework 4.8.
Typ \texttt{integer} jsme zvolili jako typ \texttt{Int32}.
Typ \texttt{string} jsme zvolili jako typ \texttt{string}.
Musíme zmínit, že jsme v sekci vstupních dat omezili znaky vstupních řetězců pouze na hodnoty ASCII [0; 127]. 

\subsubsection{Rozdělování typu Int32}

Nejdíve vytvoříme rozsah $R=[$0; $n$] pomocí úpravy rozsahu hodnot typu \texttt{Int32}.
Následně dle upraveného rozsahu vytvoříme rozdělení přihrádek.
Finálně pak sestavíme konkrétní rozsah náležící přihrádce.
\texttt{Int32} je 32-bitový typ s rozsahem $I=[$\texttt{Int32.MinValue}; \texttt{Int32.MaxValue}$]$.
Označme \texttt{Int32.MinValue} jako $I_{min}$ a \texttt{Int32.MaxValue} jako $I_{max}$.
Abychom vytvořili rozsah $R=[$0; $n$], tak přičteme ke každé hodnotě rozsahu $I$ kladnou hodnotu $I_{min}$.
Hodnotu označme $I_{+min}$.
Tímto vytvoříme rozsah $R=[0$; $I_{+min}+I_{max}$$]=[0$; 4 294 967 295] a maximální hodnotu tohoto intervalu označme $R_{max}$.
Z tohoto rozsahu nyní jednoduše určíme velikosti částí k rozdělení původního rozsahu $I$.
Počet hodnot v intervalu je $R_{max}+1$.
Velikost podintervalů je $d=(R_{max}+1)/t^2$, za předpokladu, že máme $t$ vláken.
Tedy každá přihrádka bude obsahovat právě $d$ hodnot, protože $R_{max}+1$ je dělitelné námi definovanými $t^2$.
Nyní zbývá určit jak budou vypadat samotné rozsahy přihrádek.
Pro každou přihrádku $p_i$ je rozsah $R_i=[i \cdot d; d+(i \cdot d)-1]$, což odpovídá $I_i=[I_{min}+(i \cdot d); I_{min}+d+(i \cdot d)-1]$.

K nalezení indexu $i$ správné přihrádky nyní stačí použít celočíselné dělení.
Předpokládejme, že nalezený výsledek má hodnotu prvního klíče třídění $k$.
Pomyslná nula je zde hodnota $I_{+min}$.
Pokud je $k \leq 0$, pak index přihrádky je $i=(I_{+min}-(-k))/d$.
V opačném případě je $i=(I_{+min}+k)/d$.

\subsubsection{Rozdělování typu string}

Nyní musíme rozdělit rozsah typu \texttt{string}.
Pracujeme pouze se základními znaky ASCII, ordinální hodnoty jsou v rozsahu [0; 127].
Ordinální hodnotu jednoho znaku pak budeme značit $[x]$, kde $x$ je ordinální hodnota znaku, zároveň $0\leq x\leq 127$.
Pokud budeme mluvit o hodnotě znaku, tak máme namysli ordinální hodnotu znaku.
Dále budeme postupovat jako v minulé sekci.

Abychom byli schopni definovat nějaký vhodný rozsah $R$ jako v předchozí sekci, rozhodli jsme se provádět porovnání ordinální.
Při porovnávání znaků budeme tedy uvažovat pouze jejich ordinální hodnoty a ne abecední pořadí.
Znaky [0; 31] a [127] jsou řídící kódy, které se nevykreslují.
Proto budeme považovat za adekvátní práci pouze s $128-33=95$ znaky, čili rozsah hodnot je $K=[$32; 126].
K získání rozsahu $R=[$0; $n$] odečteme hodnotu znaku [32] od každé hodnoty rozsahu $K$.
Výsledný rozsah je  $K'=[$0; 94].
Znak [32] budeme tedy chápat jako pomyslnou nulu.
Kdybychom vytvářeli přihrádky na základě jednoho znaku, tj. aktuální $K'$, tak bychom měli problém rozdělit rozsah pro větší počty vláken.
Proto jsme se rozhodli vytvořit rozsah na základě ordinálních hodnot dvou prvních znaků.
Vytváříme vlastně pomyslný skalární součin $K' \times K'$.
Uvažujeme tedy rozsah $R=[$0; $95^2-1]$, protože máme 95 znaků a děláme skalární součin.
Hodnoty znaků jsou ale stále číslovány od 0, tedy $-1$.
Označme počet hodnot v rozsahu jako $R_{max}=95^2$.

Nyní můžeme postupovat stejným způsobem jako v minulé sekci.
Velikost částí je $d=R_{max}/t^2$.
Přihrádka $p_i$ má rozsah $R_i=[d \cdot i; d+(d \cdot i)-1]$.
Určení přihrádky řetězce pak bude vypadat následovně.
Označme ordinální hodnoty prvních dvou znaků řetězce jako $[x]$ a $[y]$, kde první je $[x]$.
Pro získání indexu $i$ náležité přihrádky stačí od obou hodnot znaků odečíst hodnotu [32].
Pokud znaky chybí přiřadíme jim hodnotu 0.  
Hodnoty po odečtení označme $x'$ a $y'$.
Jejich hodnotu $q$ z rozsahu $R$ vypočteme jako $q=((x' \cdot 95)+y')$, protože každý znak se kombinoval s každým znakem.
Následně $i=q/d$.

Nastává tady problém pro velký počet vláken.
Uvažujme $t=64$, pak $d=R_{max}/4096=2$.
Jenže v momentě výpočtu $i=q/2$ bychom pro hodnoty $q>2 \cdot 4096$ získali indexy větší než počet přihrádek.  
Všimněme si, že počet problematických hodnot je zde vždy menší než počet přihrádek.
Tedy řešením daného problému je hodnoty spadající za danou hranici rozmístit do prvních $n$ přihrádek, které mají $i=0, 1, ..., n-1$.
Tyto přihrádky budou mít $d'=d+1$ a zbytek $d$.
Výpočet $i$ nyní bude vypadat následovně.
Označme hodnotu horní meze rozsahu poslední přihrádky mající $d'$ jako $D_{max}$.
Pokud $q\leq D_{max}$, pak $i=q/d'$, protože prvních $n$ rozsahů má o jednu hodnotu navíc.
V opačném případě $i=n+((q-D_{max})/d)$, jelikož od $D_{max}$ jsou rozsahy původní velikosti a předcházelo jim $n$ přihrádek.
Přičítáme $n$, protože přihrádky jsou číslované od nuly.

Tímto jsme dokončili návrh vykonávání paralelního \textit{Order by}.
Dělení popsané v předchozích kapitolách jsme určili na základě jazyka C\#.
Dané principy se dají aplikovat i v dalších jazycích.

\section{Úprava Group by} \label{anal.improvement.groupby}

\textit{Group by} má za úkol seskupit výsledky dle zadaných klíčů a vypočíst hodnoty zadaných agregačních funkcí.
Při úpravě budeme využívat původní úložiště (List a Bucket) a logiku agregačních funkcí.
Opět budeme při zpracování chtít použít hašovací tabulku jako původní řešení.
Přejdeme rovnou k návrhu zpracování módů \textbf{Streamed} a \textbf{Half-Streamed}.
Budeme uvažovat paralelní řešení, protože jednovláknové zpracování je určitý případ paralelního.

\subsection{Řešení Half-Streamed} 

V tomto módě chceme pouze upravit původní řešení \textbf{Two-step} \textit{Group by} z sekce \ref{anal.groupby.twostep}.
Má totiž stejný průběh vykonání jako model \textbf{Half-Streamed}.
Oba pracují s myšlenkou práce ve dvou krocích.
V prvním kroku dochází k lokálnímu vytváření skupin a po dokončení prohledávání grafu dojde ke slévání výsledků vláken.
Vlákno po dokončení prohledávání nečeká na dokončení práce ostatních vláken, ale rovnou výsledky slévá do sdíleného úložiště.
Zmiňovali jsme, že se jedná o paralelní mapu/slovník (C\# \texttt{ConcurrentDictionary}).
Nepoužijeme zde řešení \textbf{Local + dvoucestné slévání}, protože samotné slévání vytváří nutnost vláken čekat na dokončení práce jiného vlákna.
Pomocí řešení \textbf{Two-step} se problému kompletně vyhneme.

\subsubsection{Ukládání pouze reprezentantů skupin} \label{anal.uprava.Groupby.table}

K upravení původního řešení musíme pouze vyřešit problém chybějící tabulky výsledků, protože v momentě nalezení výsledku je výsledek předán části \textit{Group by} a není tak uložen do tabulky.
Mohli bychom výsledky opět ukládat do tabulky.
V momentě nalezení je výsledek překopírován do tabulky na nový řádek a proxy třídu řádku využijeme k jeho zpracování.
Daný způsob nám přijde neefektivní, protože cílem \textit{Group by} je vytvořit skupiny. 
K vytvoření skupin nám stačí znát pouze reprezentant skupiny, tj. klíč v hašovací tabulce (proxy třída řádku v tabulce výsledků prohledávání).
Nepotřebujeme znát všechny výsledky prohledávání, tedy nemusíme všechny výsledky kopírovat do tabulky.
Abychom mohli pouze minimálně upravit vykonávání řešení \textbf{Two-step}, tak upravíme původní tabulku výsledků na základě tohoto poznatku.
Tabulka bude nyní kromě samotných hodnot obsahovat položku držící odkaz na výsledek prohledávání.
V momentě nalezení výsledku se odkaz aktualizuje na daný výsledek a tabulka bude tento akt chápat jako přidání nového imaginárního řádku.
Při přístupu k novému řádku se vytvoří obvyklá proxy třída řádku.
Následný přístup k hodnotám řádku skrze proxy třídu vyvolá čtení hodnot z odkazu a nikoliv hodnot z tabulky.
Proxy třída se použije ke zpracování výsledku prohledávání.
Pokud byla proxy třída použita k vytvoření nové skupiny, tj. je vytvořen nový záznam v hašovací tabulce, tak je celý výsledek držený v odkazu překopírován do tabulky.
Tímto si zachováme pouze reprezentanty skupin a díky používání odkazu nemusíme každý výsledek prohledávání kopírovat do tabulky.

Zbytek zpracování bude totožný s původním řešením \textbf{Two-step}.
Úložiště hodnot agregačních funkcí bude implementováno rovněž totožně.
Platí pro něj obdobné problémy, které jsme již zmínili v sekci popisu daného zpracování \ref{anal.groupby.twostep}. 

\subsection{Řešení Streamed}

Při tomto řešení budeme vycházet z přístupu \textbf{Global} \textit{Group by} z sekce \ref{anal.groupby.global}, protože zpracovává výsledky stejným způsobem jako model \textbf{Streamed}.
Existuje zde jedna sdílená thread-safe struktura, ke které přistupují všechna vlákna.
Jedná se opět o paralelní mapu/slovník.
Předpokládejme nyní, že budeme chtít stále používat tabulky výsledků a stejná úložiště agregačních funkcí.

\subsubsection{Problém synchronizace tabulky výsledků}

Vyvstává zde opět problém neexistující tabulky výsledků.
Opět chceme ukládat pouze reprezentanty skupin.
Nicméně, problém je zde komplikovanější, protože v minulé sekci jsme tabulky vytvářeli lokálně.
Tedy v momentě slévání byly tabulky již finální. 
Aplikujeme-li nyní přístup lokálních tabulek, tak vyvstává další problém.
Vlákna v průběhu vyvolávají porovnaní klíčů v hašovací tabulce.
Klíč je zde proxy třída řádku v tabulce.
Skrze proxy třídu vlákno přistoupí k elementům na řádku tabulky.
V tuto chvíli však můžou přistupovat k hodnotám v tabulce i jiná vlákna a zároveň může docházet k rozšíření tabulky.
Pokud by docházelo k rozšiřování tabulky, tak zde dojde k souběhu a přistoupení k nevalidní tabulce.
Problém se dá řešit například použitím zámku.
Při každém přístupu k tabulce by došlo k získání zámku, následnému vyvolání porovnání nebo rozšíření a nakonec uvolnění zámku.
Řešení však přináší nutnou režii za synchronizaci tabulky, proto jsme se od řešení pomocí tabulky rozhodli kompletně upustit.

\subsubsection{Nový přístup ukládání výsledků}

Úložiště hodnot agregačních funkcí budou pořád totožná.
Místo ukládaní výsledků do tabulky vypočteme konkrétní hodnoty klíčů \textit{Group by}.
Hodnoty uložíme do pole, které následně použijeme jako klíč paralelní mapy.  
Samotné pole elementů použijeme pouze k výpočtu hodnot klíčů a k aktualizaci hodnot agregačních funkcí.
Následně jej zahodíme.
Paralelní mapa bude ve výsledku obsahovat pole hodnot klíčů a pole hodnot agregačních funkcí.
Samotné hodnoty klíčů jsou v momentě vytvoření statické, tedy nikdy nedojde ke změně hodnot klíče.
Vlákna mohou jednoduše vyvolat porovnání klíčů bez nutnosti synchronizace.

Ačkoliv se může zdát, že vytvářením mnoha malých polí povede k značné paměťové zátěži.
Musíme si uvědomit, že budeme uchovávat pouze ta pole, která byla vložena do paralelní mapy.
V typickém případě platí, že počet finálních skupin je mnohonásobně menší než počet výsledků prohledávání.
Tedy bude zde existovat pouze malá množina polí.
Otázka může být, proč jsme nezvolili daný postup i u ostatních řešení.
V původním řešení jsme drželi všechny výsledky v paměti a vytváření dalších polí spolu s překopírováváním výsledků by ještě víc vytížil paměťovou spotřebu.
V \textbf{Half-Streamed} řešení jsme způsob nepoužili, protože výsledky vláken se vytvářeli lokálně.
Kdyby každé vlákno našlo kompletně stejné skupiny, pak by existovala totožná pole pro všechna vlákna.

Další otázka je proč jsme se rozhodli uchovávat hodnoty výrazů a ne elementy grafu.
Hlavní příčina ukládání elementů jsme popsali v sekci návrhu tabulky výsledků prohledávání \ref{anal.tables}.
Tento problém zde odpadá, protože ukládáme malé množství výsledků.
Navíc v ostatních částech dotazu se mohou vyskytnout pouze výrazy klíčů \textit{Group by} a agregační funkce.
Tedy v momentě výpočtu daných výrazů a agregačních funkcí jsme získali všechny možné hodnoty, ke kterým se může přistoupit v jiných částech dotazu. 

\subsubsection{Sloučení pole klíčů a pole úložiště agregačních funkcí}

Nabízí se zde malá optimalizace za předpokladu, že budeme používat Bucket úložiště agregačních funkcí.
Bucket úložiště je pole hodnot.
Můžeme zde propojit pole hodnot klíčů a pole hodnot úložiště, protože oba pole pouze obsahují konkrétní hodnoty a logika zpracování agregačních funkcí je obsažena v objektu mimo úložiště.
Finálně bude existovat pouze jedno pole, ve kterém prvních $n$ hodnot představuje hodnoty klíčů a zbytek hodnot je považován za výsledky agregačních funkcí.
Tímto dokážeme zmenšit počet vytvářených polí.
Protože vycházíme z principu \textbf{Global} \textit{Group by} \ref{anal.groupby.global}, tak je zde problémem úložiště List.
Rozhodli jsme se výsledně dané řešení s úložištěm List neimplementovat.


\section{Úprava Single group Group by} \label{anal.improvement.singlegroup}

\textit{Single group Group by} je mód, ve kterém uživatel zadal v dotazu výpočet agregačních funkcí, ale nezadal část \textit{Group by}.
V tomto případě všechny výsledky prohledávání náleží pouze do jedné skupiny, pro kterou se počítají dané agregační funkce.
Stačí nám tedy navrhnout způsob vykonání pro naše dva módy \textbf{Streamed} a \textbf{Half-Streamed}.
Budeme uvažovat pouze paralelní řešení, protože jednovláknové bude pouze určitý případ paralelního.
Obecně si můžeme všimnout, že výsledky se nemusí ukládat do tabulky.
Po nalezení výsledku dojde k aktualizaci hodnot agregačních funkcí a výsledek není dále potřeba.
Ušetříme tedy spoustu paměti za tabulku výsledků.
Samotný výpočet hodnot funkcí a úložiště hodnot budou totožné s původním řešením.

\subsection{Řešení Half-Streamed}

V tomto módu každé vlákno počítá hodnoty agregačních funkcí lokálně.
Po nalezení výsledku dojde k aktualizování lokálních hodnot agregačních funkcí.
V momentě dokončení prohledávání grafu všemi vlákny dojde ke slévání výsledků vláken.
Vlákno však nebude čekat na ukončení práce ostatních vláken, ale rovnou výsledky slévá do globální struktury.
Výhoda tohoto řešení je vyřazení nutnosti používat thread-safe logiku agregačních funkcí v lokální části.

\subsection{Řešení Streamed}

V tomto módu existuje pouze jedno sdílené úložiště hodnot agregačních funkcí.
Vlákna v momentě nalezení výsledku aplikují thread-safe agregační funkce.
Výhoda tohoto řešení je, že zde nedochází ke slévání výsledků.
Problém zde může nastat ve chvíli, kdy existuje velké množství přistupujících vláken.
Tyto přístupy mohou mít za následek značné zpomalení zpracování, kvůli synchronizaci.

Všimněme si také, že v jednovláknovém zpracování jsou módy totožné.
V obou případech se nemusí použít thread-safe logika agregačních funkcí a existuje pouze jedno úložiště hodnot.
Módy se tedy liší jen způsobem paralelního zpracování.