\chapter*{Závěr}
\addcontentsline{toc}{chapter}{Závěr}

Vytvořili jsme dotazovací engine dle zadaných požadavků.
Dotazovací engine se skládá ze dvou částí.
První část je statická grafová databáze využívající Labeled-property model grafových dat. 
Druhá část obsahuje struktury a algoritmy pro vykonání uživatelských dotazů nad grafovou databází.
Dotazy jsou zadány ve stanovené podmnožině jazyka PGQL.
Vykonávání je možno provádět jednovláknově i paralelně.
Všechna grafová data a data v průběhu zpracování dotazu jsou obsažena v hlavní paměti.
Druhou část jsme rozdělili na dva bloky:
\begin{enumerate}
\item
První blok představuje mód \textbf{Normal}.
Mód reprezentuje řešení vykonávající \textit{Group/Order by} po dokončení prohledávání grafu v části \textit{Match}.
Výsledky prohledávání byly ukládány do tabulky.
Teprve po získání všech výsledků byly na výsledcích aplikovány algoritmy \textit{Group/Order by}.
\begin{itemize}
\item V části \textit{Order by} jsme použili standardní algoritmus Merge sort pro jednovláknové i paralelní zpracování.
\item V části \textit{Group by} jsme výsledky seskupovali pomocí hašovací tabulky.
Pro paralelní zpracování jsme zvolili tři řešení dle úrovně synchronizace (sekce \ref{anal.groupby.paralel}).
V módu \textit{Single group Group by} (dotaz obsahuje agregační funkce, ale neobsahuje část \textit{Group by}) jsme využili lokálního zpracování, které je zakončeno sléváním.
\end{itemize}

\item
Druhý blok představuje dva módy \textbf{Half-Streamed} a \textbf{Streamed}, které odpovídají navrženým řešením dle zadání práce.
Pro oba módy jsme propojili prohledávání grafu se zpracováním částí \textit{Group/Order by} tak, aby dané části byly vykonávány v průběhu prohledávání grafu.
To znamená, že v moment nalezení výsledku prohledávání se výsledek okamžitě zatřídí nebo seskupí.
Obecně se módy liší v paralelních řešeních. 
\textbf{Half-Streamed} zpracovával výsledky lokálně, následně docházelo ke slévání.
\textbf{Streamed} zpracovával výsledky globálně.
\begin{itemize}
\item V části \textit{Order by} jsme pro jednovláknové zpracování použili standardní $(a, 2a)$-strom a upravenou verzi $(a, 2a)$-stromu, která omezila počet zatřiďovaných výsledků.  
\textbf{Half-Streamed} řešení zpracovávalo lokálně výsledky pomocí navržených stromů a následně došlo k dvoucestnému paralelnímu slévání.
\textbf{Streamed} řešení vytvořilo přihrádky přístupné skrze zámek a každé přihrádce přiřadilo specifický rozsah hodnot.
\item
V části \textit{Group by} jsme vycházeli z řešení prvního bloku.
Jednovláknové a paralelní zpracování \textbf{Half-Streamed} používalo tabulku z prvního bloku.
Obecně jsme u něj omezili ukládané výsledky pouze na reprezentanty skupin.
Jednovláknové a paralelní zpracování \textbf{Streamed} nepoužívalo žádnou tabulku.
Zpracování \textit{Single group Group by} neukládalo žádné výsledky, kromě výsledků agregačních funkcí.
\end{itemize}
\end{enumerate}

Navržené módy jsme porovnali v rychlosti vykonávání dotazů pomocí experimentu.
Experiment obsahoval množství dotazů, které byly vykonány nad třemi reálnými grafy s uměle vygenerovanými vlastnostmi.
Otestovali jsme jednovláknové zpracování a paralelní zpracování využívající osm vláken.
Při experimentu jsme měřili práci pouze \textit{Match} části s \textit{Group/Order by}, tj. výsledky neobsahují práci \textit{Select} části.
Následuje shrnutí výsledků:
\begin{itemize}

\item \textit{Order by:} z výsledků \textit{Order by} vyplynulo, že módy \textbf{Half-Streamed} a \textbf{Streamed} využívající $(a, 2a)$-stromy jsou obecně pomalejší než řešení módu \textbf{Normal} využívající Merge sort.
Nicméně, námi navržená paralelní řešení módu \textbf{Streamed} předčila paralelní Merge sort módu \textbf{Normal} při třídění pomocí vlastností.

\item \textit{Group by:} u řešení \textit{Group by} módů \textbf{Half-Streamed} a \textbf{Streamed} nedocházelo ke znatelnému zrychlení vůči módu \textbf{Normal}.
Jedinou výjimkou bylo jednovláknové řešení \textbf{Streamed} módu, které bylo nejrychlejší.

\item \textit{Single group Group by:} zde byla řešení módů \textbf{Half-Streamed} a \textbf{Streamed} obecně rychlejší.
Problematické zde bylo paralelní řešení módu \textbf{Streamed}, ve kterém docházelo ke zpomalení, kvůli značné režii za synchronizaci.

\end{itemize}

Hlavním cílem této práce bylo zjistit, zda upravením částí zabývajících se agregací dat (tj. části  \textit{Group/Order by}) dotazovacího enginu po vzoru proudových systémů urychlíme vykonávání dotazů.
Danou úpravu představují navržená řešení módů \textbf{Half-Streamed} a \textbf{Streamed}.
Původní vykonávání představují řešení módu \textbf{Normal}.
Z výsledků experimentu výše můžeme vyvodit, že existují situace, kdy nastává urychlení vykonávání.
Konkrétně nastalo zrychlení v paralelním zpracování \textit{Order by} módů \textbf{Half-Streamed} a \textbf{Streamed} při třídění pomocí vlastností.
Dále nastalo urychlení v jednovláknovém zpracování \textit{Group by} módu \textbf{Streamed}, kdy nebyla použita tabulka výsledků prohledávání.
Posledně nastalo urychlení v paralelním i jednovláknovém zpracování \textit{Single group Group by} módu \textbf{Half-Streamed}, kdy docházelo k uchovávání pouze hodnot agregačních funkcí.

\section*{Budoucí výzkum a rozšíření}

\begin{enumerate}

\item 
Rozšíření enginu o možnost zadat \textit{Order by} a \textit{Group by} společně.
Agregování v průběhu hledání se dá rozdělit na dvě hlavní části.
V první části lze navrhnout řešení pro dotazy, ve kterých část \textit{Order by} obsahuje pouze výrazy seskupování z části \textit{Group by}.
Zde lze například aplikovat podobný přístup řešení \textbf{ABTreeValueAccumulator} části \textit{Order by}, ve kterém se výsledky se stejnými klíči třídění seskupovaly do pole.
Nyní místo seskupování do pole bude stromová struktura obsahovat pouze reprezentanty skupin a jejich úložiště hodnot agregačních funkcí.
V druhé části je nutné vyřešit dotazy, které v části \textit{Order by} obsahují výrazy agregačních funkcí.
Zde je největší problém fakt, že výsledky agregačních funkcí jsou známy pouze po dokončení \textit{Group by}.

\item Testování daných řešení na grafech s reálnými vlastnostmi.
V našem experimentu jsme sice volili reálné grafy, ale jejich vlastnosti jsme uměle vygenerovali.

\item Sledování obecného problému rozdělení dat při paralelizaci vylepšených řešení. 
\textbf{Normal} přistup má vždy všechna data připravená v paměti a při zpracování je rovnoměrně rozděluje mezi vlákny.
Vlákna tedy mají vždy stejný počet výsledků pro zpracování.
Navíc díky kompletnosti dat lze data optimálněji zpracovávat a použít větší množství obecných algoritmů.
Například při třídění jsme použili základní algoritmus Merge sort, který není možný aplikovat při třídění v průběhu vyhledávání.  
Rozdělení práce vylepšených řešení závisí na počtu vyhledaných výsledků v každém vlákně.
Mohou nastávat případy, kdy jedno vlákno má více výsledků ke zpracování než ostatní. 
Daný problém jsme se v našem řešení prohledávání snažili vyřešit pomocí přidělování malých skupin vrcholů vláknům.
Vlákno po prohledání daných vrcholů zažádalo o další.
Nicméně, dané řešení nemůže zaručit stoprocentně rovnoměrné rozdělení práce.
Bylo by vhodné prozkoumat, jak daná situace ovlivňuje naše řešení.

\item \textit{Order by}:
\begin{enumerate}

\item
U paralelního řešení jsme viděli značné zrychlení při třídění pomocí vlastností.
Bylo by vhodné prozkoumat možnosti vytvoření globálních statistik pro každou vlastnost a podrobněji zjistit možnosti rozdělení rozsahů použitým přihrádkám.
\item
V našem řešení jsme rozdělení přihrádek pro řetězce zpracovali pouze s předpokladem, že se jedná o ASCII znaky.
V budoucí práci je možné zkoumat rozdělování i pro složitější znakové sady.
\item
Obecně \textit{Order by} řešení využívaly implementaci $(a, 2a)$-stromu.
Daná implementace má značnou režii za metodu \texttt{Insert}, při které dochází k časté alokaci nových vrcholů.
V budoucích rozšířeních je možné vyzkoušet předalokovat určitou množinu vrcholů stromu, které se následně využijí v dané metodě.
\end{enumerate}

\item V paralelních \textit{Group by} řešeních by bylo vhodné prozkoumat podrobněji škálovatelnost daných řešení pro rozličné počty vláken.
Pokud možno, také možnosti jiných paralelních map/slovníků.
 
\item
Dotazy v našem dotazovacím enginu jsou zadávány pomocí podmnožiny jazyka PGQL.
Při implementaci jsme se snažili oddělit načítání dotazu od zpracování dotazu.
K tokenizaci jsme použili třídu \texttt{Tokenizer}, pro vytvoření syntaktických stromů jsme použili třídu \texttt{Parser} a k procházení vzniklých stromů jsme implementovali rozhraní \texttt{IVisitor}.
Procházením stromů vznikají struktury, které se následně využijí při zpracování dotazu.
Obecně tokenizace a vytvoření syntaktických stromů je odděleno od zpracování dotazu.
Při použití jiného jazyka stačí implementovat dané dvě části separátně.
Problém nastane v rozhraní \texttt{IVisitor} a vzniku struktur dotazu, protože konstruktory tříd \texttt{Query} a \texttt{QueryObject} očekávají stávající formát.
Nicméně, dané konstruktory a rozhraní \texttt{IVisitor} se dají jednoduše upravit k použití nového formátu.
Přínosem je pak možnost využít i jiné dotazovací jazyky za cenu malých úprav.
Dalším přínosem je také možnost využít třídu \texttt{Tokenizer} a \texttt{Parser} jako separátní knihovnu k načítání PGQL dotazu pro jazyk C\#, protože dle našeho průzkumu neexistuje v C\# knihovna pro práci s PGQL. 

\item
V budoucích rozšířeních lze uvažovat nad vypracováním důmyslnějšího exekučního plánu prohledávání v části \textit{Match}.
Exekučním plánem zde myslíme vrcholy, ze kterých začíná prohledávání grafu.
V našem případě jsme pouze vytvořili souvislé komponenty z posloupností v části dotazu \texttt{Match} (sekce \ref{anal.match} a \ref{impl.match}).
Obecně lze však využít efektivnější přístupy.
Například dojde k rozšíření dotazovacího enginu o část dotazu \textit{Where} (ekvivalent SQL \textit{Where}) a uživatel zadá dotaz \texttt{select count(*) match (x) -> (y) -> (z) where z.Vlastnost == 42}.
Zde se jeví jako efektivnější přístup spustit prohledávání z vrcholu \texttt{z} a hledat vzor \texttt{(z) <- (y) <- (x)}, protože již v prvním kroku můžeme zjistit, že existuje jen pár vrcholů \texttt{z} splňujících podmínku \textit{Where}.
V našem případě by však došlo ke spuštění prohledávání z proměnné \texttt{x}.
Výsledně bychom procházeli první dva vrcholy \texttt{x} a \texttt{y} zbytečně, když následně zjistíme, že pro ně žádný vrchol \texttt{z} neexistuje.

\end{enumerate}



