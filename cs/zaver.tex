\chapter*{Závěr}
\addcontentsline{toc}{chapter}{Závěr}

Vytvořili jsme dotazovací engine dle zadaných požadavků.
Engine se skládá ze dvou částí.
První část je statická grafová databáze využívající Labeled-property model grafových dat. 
Druhá část obsahuje struktury a algoritmy pro vykonání uživatelských dotazů nad grafovou databází.
Dotazy jsou zadány ve stanovené podmnožině jazyka PGQL.
Vykonávání je možno provádět jednovláknově i paralelně.
Všechna grafová data a data v průběhu zpracování dotazu jsou obsažena v hlavní paměti.
Druhou část jsme rozdělili na dva bloky:
\begin{enumerate}
\item
V prvním bloku jsme navrhli řešení vykonávající \textit{Group/Order by} po dokončení prohledávání grafu v části \textit{Match}.
Výsledky prohledávání byly ukládány do tabulky.
Teprve po získání všech výsledků byly na výsledcích aplikovány algoritmy \textit{Group/Order by}.
\begin{itemize}
\item V části \textit{Order by} jsme použili standartní algoritmus Merge sort pro jednovláknové i paralelní zpracování.
\item V části \textit{Group by} jsme výsledky seskupovali pomocí hašovací tabulky.
Pro paralelní zpracování jsme zvolili tři řešení dle úrovně synchronizace (sekce \ref{anal.groupby.paralel}).
V módu \textit{Single group Group by} (dotaz obsahuje agregační funkce, ale neobsahuje část \textit{Group by}) jsme využili lokálního zpracování, které je zakončeno sléváním.
\end{itemize}

\item
V druhém bloku jsme upravili první blok a navrhli nová řešení zpracování dle zadání práce.
Propojili jsme prohledávání grafu se zpracováním \textit{Group/Order by} tak, aby engine seskupoval/setřiďoval výsledky prohledávání v moment jejich nalezení.
Pro paralelní zpracování jsme navrhli dva módy: \textbf{Streamed} a \textbf{Half-Streamed}.
\textbf{Streamed} zpracovával výsledky globálně.
\textbf{Half-Streamed} zpracovával výsledky lokálně, následně docházelo ke slévání.
\begin{itemize}
\item V části \textit{Order by} jsme pro jednovláknové zpracování použili standartní $(a, 2a)$-strom a upravenou verzi $(a, 2a)$-stromu, která omezila počet zatříďovaných výsledků.  
\textbf{Half-Streamed} řešení zpracovávalo lokálně výsledky pomocí navržených stromů a následně došlo k dvoucestnému paralelnímu slévání.
\textbf{Streamed} řešení vytvořilo přihrádky přistupné skrze zámek a každé přihrádce přiřadilo specifický rozsah hodnot.
\item
V části \textit{Group by} jsme vycházeli z řešení prvního bloku.
Jednovláknové a paralelní zpracování \textbf{Half-Streamed} používalo tabulku z prvního bloku.
Obecně jsme u něj omezeli ukládané výsledky pouze na reprezentanty skupin.
Jednovláknové a paralelní zpracování \textbf{Streamed} nepoužívalo žádnou tabulku.
Zpracování \textit{Single group Group by} neukládalo žádné výsledky, kromě výsledků agregačních funkcí.
\end{itemize}
\end{enumerate}

Dva dané bloky jsme porovnali v rychlosti vykonávání dotazů pomocí experimentu.
Experiment obsahoval množství dotazů, které byly vykonány nad třemi reálnými grafy s uměle vygenerovanými vlastnostmi.
Otestovali jsme jednovláknové zpracování a paralelní zpracování využívající osm vláken.
Při experimentu jsme měřili práci pouze \textit{Match} části s \textit{Group/Order by}, tj. výsledky neobsahují práci \textit{Select} části.
Následuje shrnutí výsledků:
\begin{itemize}

\item \textit{Order by:} z výsledků \textit{Order by} vyplynulo, že řešení druhého bloku využívající $(a, 2a)$-stromy jsou obecně pomalejší než řešení v prvním bloku využívající Merge sort.
Nicméně, námi navržená paralelní řešení druhého bloku předčila paralelní Merge sort prvního bloku při třídění pomocí vlastností.

\item \textit{Single group Group by:} zde byla řešení druhého bloku rychlejší.
Problematické zde bylo paralelní \textbf{Streamed} řešení, ve kterém docházelo ke zpomalení, kvůli značné režii za synchronizaci.

\item \textit{Group by:} u řešení \textit{Group by} druhého bloku nedocházelo ke znatelnému zrychlení.
Jedinou výjimkou bylo \textbf{Streamed} řešení druhého bloku v jednovláknovém zpracování, které bylo nejrychlejší.

\end{itemize}

Z výsledků experimentu můžeme konstatovat, že naše předpoklady o zpracovávání \textit{Group by} a \textit{Order by} v průběhu prohledávání grafu nabízí v určitých případech zrychlení vykonávání dotazů.

\section*{Budoucí výzkum a rozšíření}

\begin{enumerate}

\item 
Rozšíření enginu o možnost zadat \textit{Order by} a \textit{Group by} společně.
Agregování v průběhu hledání se dá rozdělit na dvě hlavní části.
V první části lze navrhnout řešení pro dotazy, ve kterých část \textit{Order by} obsahuje pouze výrazy seskupování z části \textit{Group by}.
Zde lze například aplikovat podobný přístup řešení \textbf{ABTreeValueAccumulator} části \textit{Order by}, ve kterém se výsledky se stejnými klíči třídění seskupovaly do pole.
Nyní místo seskupování do pole bude stromová struktura obsahovat pouze reprezentanty skupin a jejich úložiště hodnot agregačních funkcí.
V druhé části je nutné vyřešit dotazy, které v části \textit{Order by} obsahují výrazy agregačních funkcí.
Zde je největší problém fakt, že výsledky agregačních funkcí jsou známy pouze po dokončení \textit{Group by}.

\item Testování daných řešení na grafech s reálnými vlastnostmi.
V našem experimentu jsme sice volili reálne grafy, ale jejich vlastnosti jsme uměle vygenerovali.

\item Sledování obecného problému rozdělení dat při paralelizaci vylepšených řešení. 
Normal přistup má vždy všechna data připravená v paměti a při zpracování je rovnoměrně rozděluje mezi vlákny.
Vlákna tedy mají vždy stejný počet výsledků pro zpracování.
Navíc díky kompletnosti dat lze data optimálněji zpracovávat a použít větší množství obecných algoritmů.
Například při třídění jsme použili základní algoritmus Merge sort, který není možný aplikovat při třídění v průběhu vyhledávání.  
Rozdělení práce vylepšených řešení závísí na počtu vyhledaných výsledků v každém vlákně.
Mohou nastávát případy, kdy jedno vlákno má více výsledků ke zpracování než ostatní. 
Daný problém jsme se v našem řešení prohledávání snažili vyřešit pomocí přidělování malých skupin vrcholů vláknům.
Vlákno po prohledání daných vrcholů zažádalo o další.
Nicméně, dané řešení nemůže zaručit stoprocentně rovnoměrné rozdělení práce.
Bylo by vhodné prozkoumat, jak daná situace ovlivňuje naše řešení.

\item \textit{Order by}:
\begin{enumerate}

\item
U paralelního řešení jsme viděli značné zrychlení při třídění pomocí vlastností.
Bylo by vhodné prozkoumat možnosti vytvoření globálních statistik pro každou vlastnost a podrobněji zjistit možnosti rozdělení rozsahů použitým přihrádkám.
\item
V našem řešení jsme rozdělení přihrádek pro řetězce zpracovali pouze s předpokladem, že se jedná o ASCII znaky.
V budoucí práci je možné zkoumat rozdělování i pro složitější znakové sady.
\item
Obecně \textit{Order by} řešení využívaly implementaci $(a, 2a)$-stromu.
Daná implementace má značnou režii za metodu \texttt{Insert}, při které dochází k časté alokaci nových vrcholů.
V budoucích rozšířeních je možné vyzkoušet předalokovat určitou množinu vrcholů stromu, které se následně využijí v dané metodě.
\end{enumerate}

\item V paralelních \textit{Group by} řešeních by bylo vhodné prozkoumat podrobněji škálovatelnost daných řešení pro rozličné počty vláken.
Pokud možno, také možnosti jiných paralelních map/slovníků.
 
\item
Dotazy v našem dotazovacím enginu jsou zadávány pomocí podmnožiny jazyka PGQL.
Při implementaci jsme se snažili oddělit načítání dotazu od zpracování dotazu.
K tokenizaci jsme použili třídu \texttt{Tokenizer}, pro vytvoření syntaktických stromů jsme použili třídu \texttt{Parser} a k procházení vzniklých stromů jsme implementovali rozhraní \texttt{IVisitor}.
Procházením stromů vznikají struktury, které se následně využijí při zpracování dotazu.
Obecně tokenizace a vytvoření syntaktických stromů je odděleno od zpracování dotazu.
Při použití jiného jazyka stačí implementovat dané dvě části separátně.
Problém nastave v rozhraní \texttt{IVisitor} a vzniku struktur dotazu, protože konstruktory tříd \texttt{Query} a \texttt{QueryObject} očekávají stávající formát.
Nicméně, dané konstruktory a rozhraní \texttt{IVisitor} se dají jednoduše upravit k použití nového formátu.
Přínosem je pak možnost využít i jiné dotazovací jazyky za cenu malých úprav.
Dalším přínosem je také možnost využít třídu \texttt{Tokenizer} a \texttt{Parser} jako separátní knihovnu k načítání PGQL dotazu.

\end{enumerate}



